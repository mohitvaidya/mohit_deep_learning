{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample snippet showing tf.function and eager execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=25, shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0.89445204, 0.7446816 , 0.36253726, 0.47863898, 0.7283995 ],\n",
       "       [0.79431707, 0.7167271 , 0.5470558 , 0.35135847, 0.77774364]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the forward pass\n",
    "@tf.function\n",
    "def single_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "# Generate random data drawn from a uniform distribution\n",
    "x = tf.random.uniform((2, 3))\n",
    "y = tf.random.uniform((3, 5))\n",
    "\n",
    "# by default eager execution is enabled\n",
    "# can be disabled by using  tf.compat.v1.disable_eager_execution()\n",
    "single_layer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that you did not have to create any sessions or placeholders to run the function single_layer(). \n",
    "- This is one of the nifty features of tf.function. Behind the hood, it does all the necessary optimizations so that your code runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"]\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
    "                    header=None,\n",
    "                    names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import qgrid\n",
    "# qgrid.show_grid(data,show_toolbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode\n",
    "le = LabelEncoder()\n",
    "data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2671</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2926</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14086</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15336</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19355</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  Occupation  \\\n",
       "0   22          7    2671          9            12              4           1   \n",
       "1   33          6    2926          9            12              2           4   \n",
       "2   21          4   14086         11             8              0           6   \n",
       "3   36          4   15336          1             6              2           6   \n",
       "4   11          4   19355          9            12              2          10   \n",
       "\n",
       "   Relationship  Race  Gender  CapitalGain  CapitalLoss  HoursPerWeek  \\\n",
       "0             1     4       1           25            0            39   \n",
       "1             0     4       1            0            0            12   \n",
       "2             1     4       1            0            0            39   \n",
       "3             0     2       1            0            0            39   \n",
       "4             5     2       0            0            0            39   \n",
       "\n",
       "   NativeCountry  Income  \n",
       "0             39       0  \n",
       "1             39       0  \n",
       "2             39       0  \n",
       "3             39       0  \n",
       "4              5       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate data features & convert into NumPy arrays\n",
    "X = data.iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2671</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2926</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14086</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15336</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19355</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1      2   3   4   5   6   7   8   9   10  11  12  13\n",
       "0  22   7   2671   9  12   4   1   1   4   1  25   0  39  39\n",
       "1  33   6   2926   9  12   2   4   0   4   1   0   0  12  39\n",
       "2  21   4  14086  11   8   0   6   1   4   1   0   0  39  39\n",
       "3  36   4  15336   1   6   2   6   0   2   1   0   0  39  39\n",
       "4  11   4  19355   9  12   2  10   5   2   0   0   0  39   5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Income'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dropout(rate=0.2, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00870994]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " ...\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], shape=(26048, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Get the output probabilities\n",
    "out_probs = model(X_train.astype(np.float32), training=True)\n",
    "print(out_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above we have done only the forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/5\n",
      "26048/26048 [==============================] - 1s 32us/sample - loss: 0.5586 - val_loss: 0.5482\n",
      "Epoch 2/5\n",
      "26048/26048 [==============================] - 1s 23us/sample - loss: 0.5444 - val_loss: 0.5483\n",
      "Epoch 3/5\n",
      "26048/26048 [==============================] - 1s 24us/sample - loss: 0.5419 - val_loss: 0.5483\n",
      "Epoch 4/5\n",
      "26048/26048 [==============================] - 1s 24us/sample - loss: 0.5348 - val_loss: 0.5481\n",
      "Epoch 5/5\n",
      "26048/26048 [==============================] - 1s 24us/sample - loss: 0.5324 - val_loss: 0.5481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2f4204f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable parameters in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(14, 64) dtype=float32, numpy=\n",
       " array([[ 1.46168754e-01, -2.43844017e-01,  1.05756059e-01,\n",
       "          7.65478984e-02, -9.77647603e-02, -3.82975280e-01,\n",
       "         -6.63518393e-03,  2.62320247e-02, -1.98453739e-02,\n",
       "          2.12402549e-02,  4.49184738e-02, -1.43168435e-01,\n",
       "          7.59668797e-02, -1.88478366e-01,  1.13383196e-01,\n",
       "         -1.04053915e-01, -1.28447253e-03, -1.39247224e-01,\n",
       "          1.09164901e-01,  4.21509184e-02, -2.22265601e-01,\n",
       "         -2.63643801e-01,  3.04695424e-02, -1.79906607e-01,\n",
       "         -1.92752302e-01, -1.87018797e-01, -9.16395038e-02,\n",
       "         -1.73275083e-01, -5.36628142e-02, -4.42804471e-02,\n",
       "         -1.30713940e-01, -2.40382478e-01, -1.09530516e-01,\n",
       "          3.17444414e-01,  2.40139559e-01, -4.39635575e-01,\n",
       "          4.65867184e-02, -4.58263420e-02, -2.98312940e-02,\n",
       "          7.42737278e-02,  1.46892205e-01,  2.53466889e-02,\n",
       "         -4.89447359e-03, -1.52300775e-01, -1.75191239e-01,\n",
       "         -5.73777854e-02,  9.16801170e-02, -7.61738867e-02,\n",
       "         -1.98967718e-02, -2.62881070e-01, -1.95383579e-01,\n",
       "         -1.44087717e-01, -1.70323074e-01, -1.91961855e-01,\n",
       "          5.93949966e-02, -8.75449106e-02, -1.48243099e-01,\n",
       "         -5.72567768e-02,  6.94633424e-02, -6.16749264e-02,\n",
       "         -1.78008467e-01,  2.51770467e-01, -5.38900681e-02,\n",
       "         -2.06992596e-01],\n",
       "        [ 3.38925347e-02, -1.53413579e-01, -1.89669505e-01,\n",
       "         -7.23193679e-03, -5.01451679e-02, -2.71986835e-02,\n",
       "         -2.00951114e-01,  1.15630277e-01, -1.82797015e-02,\n",
       "         -2.73465753e-01, -1.99544877e-02, -2.54516095e-01,\n",
       "         -2.89169073e-01, -2.03514904e-01, -6.70684129e-02,\n",
       "          1.75753608e-02,  1.85558096e-01,  3.33907232e-02,\n",
       "         -2.48920262e-01, -2.06492469e-01,  1.63012594e-01,\n",
       "         -1.19228154e-01, -2.58760124e-01, -2.98422933e-01,\n",
       "          2.51129065e-02,  2.47224003e-01,  1.19647548e-01,\n",
       "          2.90879428e-01,  1.16865002e-01,  6.51012063e-02,\n",
       "         -1.27872810e-01, -3.47039521e-01, -2.73075372e-01,\n",
       "          2.18407124e-01, -2.98405170e-01,  1.93812754e-02,\n",
       "         -3.85251820e-01,  1.73000410e-01, -2.36389175e-01,\n",
       "         -6.50765449e-02,  2.33241171e-02, -8.05607140e-02,\n",
       "         -2.20600203e-01, -2.59618908e-01, -1.00789621e-01,\n",
       "         -1.71145171e-01,  1.07129347e-02,  4.30654079e-01,\n",
       "          2.20004618e-01, -2.08658651e-01, -2.90831011e-02,\n",
       "         -2.78232694e-01, -1.49219245e-01,  1.83569789e-01,\n",
       "         -3.87102887e-02, -1.44902945e-01,  1.49806932e-01,\n",
       "          1.33908942e-01,  2.76529528e-02, -7.58378059e-02,\n",
       "          3.45080137e-01, -2.11969167e-01,  5.85043291e-03,\n",
       "         -1.86652496e-01],\n",
       "        [-9.85584557e-02, -2.57200807e-01, -4.24959995e-02,\n",
       "          1.48231655e-01, -8.86487141e-02,  1.16847679e-01,\n",
       "          5.47575466e-02, -3.03303283e-02, -2.04266354e-01,\n",
       "          7.11485557e-03,  4.05116789e-02, -1.31274745e-01,\n",
       "         -2.02737600e-02,  1.05665736e-01, -3.74770433e-01,\n",
       "          1.08795628e-01, -4.58709151e-02, -2.94674784e-01,\n",
       "         -1.93876252e-02,  3.98076884e-02,  8.70968252e-02,\n",
       "         -1.08466126e-01,  1.46436915e-01, -1.18350498e-02,\n",
       "         -2.92310235e-03, -8.16658065e-02,  6.42363355e-02,\n",
       "          9.18772817e-02, -1.92155074e-02, -1.12446491e-02,\n",
       "          9.37727541e-02,  8.92940536e-02, -1.99424587e-02,\n",
       "          1.07577115e-01,  1.21536225e-01, -3.47717619e-03,\n",
       "         -2.02498779e-01, -1.50283342e-02, -2.45764524e-01,\n",
       "         -8.68474171e-02, -2.27079719e-01, -4.50899750e-02,\n",
       "         -9.09198634e-03, -4.58120257e-02,  8.75204057e-02,\n",
       "         -1.95343569e-02,  9.13253352e-02,  2.26768285e-01,\n",
       "         -2.48996541e-02,  1.07092224e-01,  1.15450434e-01,\n",
       "         -1.15661528e-02, -1.45905852e-01, -1.92295387e-01,\n",
       "          6.87092990e-02, -8.37394372e-02,  8.44118148e-02,\n",
       "          5.45045771e-02, -6.95143864e-02,  6.18264414e-02,\n",
       "          1.08155808e-04,  1.43786445e-01,  1.72300071e-01,\n",
       "         -1.14829848e-02],\n",
       "        [-2.38322131e-02, -1.93627313e-01,  5.54129481e-02,\n",
       "          2.38882735e-01,  1.52464062e-01,  7.05314726e-02,\n",
       "          7.70576745e-02, -2.49501318e-02,  4.39361818e-02,\n",
       "         -2.63519436e-02, -2.18467101e-01, -2.81696338e-02,\n",
       "          6.91028088e-02,  2.49322608e-01,  2.72735089e-01,\n",
       "         -3.03664953e-01,  1.37261882e-01, -8.60992372e-02,\n",
       "          1.29151687e-01,  1.83451042e-01, -3.69498469e-02,\n",
       "         -8.46412852e-02, -2.19430327e-01, -3.40591282e-01,\n",
       "          6.94419583e-03,  3.14760506e-02, -5.69860302e-02,\n",
       "         -9.81702879e-02,  1.85316443e-01, -1.94505900e-01,\n",
       "         -1.08371027e-01, -2.95415580e-01,  1.53472990e-01,\n",
       "         -4.07692157e-02, -2.82319844e-01,  2.54399665e-02,\n",
       "         -2.80921817e-01, -2.29113102e-02,  7.23014772e-02,\n",
       "          8.30065832e-02,  1.84077114e-01, -2.18588095e-02,\n",
       "         -1.57118104e-02, -9.68224853e-02, -1.55348197e-01,\n",
       "          4.91844602e-02, -8.33200887e-02,  1.52088523e-01,\n",
       "          5.84059469e-02, -1.43785581e-01,  3.15274298e-01,\n",
       "         -2.95127660e-01,  1.65734500e-01, -2.74825066e-01,\n",
       "          9.62782428e-02, -1.70008391e-01, -1.89651430e-01,\n",
       "         -1.89956605e-01, -1.56907085e-02, -9.98869613e-02,\n",
       "         -5.88756017e-02, -1.25570819e-01,  1.09939324e-02,\n",
       "         -1.34034708e-01],\n",
       "        [ 1.42897636e-01,  1.38256192e-01, -3.29712629e-01,\n",
       "         -1.20614611e-01,  1.68863200e-02,  1.26923984e-02,\n",
       "         -2.05454901e-01, -1.12453431e-01,  1.54659674e-01,\n",
       "          6.49228832e-03, -8.03336874e-03,  2.09854349e-01,\n",
       "          3.71633619e-01, -2.04848379e-01, -1.48235383e-02,\n",
       "         -2.22313523e-01, -1.26683772e-01, -2.06079826e-01,\n",
       "         -9.69598964e-02,  5.60421273e-02,  2.32767135e-01,\n",
       "          7.41667226e-02,  2.64179800e-02, -2.40170360e-01,\n",
       "         -8.08779001e-02,  1.39845638e-02,  9.43977758e-02,\n",
       "         -6.67296201e-02, -5.69102690e-02, -3.43422182e-02,\n",
       "         -3.16408813e-01,  1.25516534e-01, -1.74739748e-01,\n",
       "         -7.69795328e-02, -6.19510934e-02, -3.54170382e-01,\n",
       "         -8.85393843e-02,  2.90199518e-01,  1.91939980e-01,\n",
       "          3.02252889e-01, -2.26646572e-01,  1.42807728e-02,\n",
       "         -2.98504591e-01,  1.03125766e-01,  6.31234869e-02,\n",
       "         -6.74111098e-02, -1.34839490e-01,  3.19732688e-02,\n",
       "         -2.46980369e-01, -2.83668842e-02,  1.57351285e-01,\n",
       "          5.78387827e-02, -2.57905632e-01, -2.27561206e-01,\n",
       "          7.36397132e-02, -8.97400379e-02,  2.92796671e-01,\n",
       "          3.13339055e-01, -2.38310248e-02, -2.77764410e-01,\n",
       "          1.84283137e-01, -6.21548817e-02,  1.37422591e-01,\n",
       "         -1.69188023e-01],\n",
       "        [ 2.30262563e-01, -7.34398291e-02, -6.20779768e-02,\n",
       "         -7.30418921e-01, -3.78764123e-01, -5.20478964e-01,\n",
       "         -6.15359750e-04, -3.81269574e-01, -4.29989129e-01,\n",
       "         -4.09168005e-01, -3.91498983e-01, -9.36554372e-02,\n",
       "         -4.40676898e-01, -1.37049600e-01, -2.99004704e-01,\n",
       "         -2.05495536e-01,  2.44129375e-01,  1.06279284e-01,\n",
       "         -7.30586708e-01, -6.72877282e-02, -6.01314843e-01,\n",
       "          3.43754947e-01, -2.49232382e-01, -3.36814940e-01,\n",
       "          3.25931966e-01,  1.80989042e-01, -2.88637757e-01,\n",
       "         -5.41250765e-01,  1.05467713e+00, -4.14683133e-01,\n",
       "         -4.35326360e-02, -1.05898894e-01, -2.04847977e-01,\n",
       "         -3.97714853e-01, -4.16131020e-01, -3.01494654e-02,\n",
       "         -1.18332185e-01, -4.24992412e-01, -4.61934179e-01,\n",
       "         -2.17881322e-01,  3.00110281e-01,  9.91824150e-01,\n",
       "         -1.25629921e-03,  6.11892700e-01,  4.52657975e-02,\n",
       "          9.34752107e-01, -8.64017010e-02,  3.16726297e-01,\n",
       "          3.09189081e-01, -1.12766057e-01,  7.71824121e-02,\n",
       "          9.88581479e-02, -6.29971772e-02,  2.24437937e-01,\n",
       "          7.67280534e-02, -2.39834860e-01, -9.88239869e-02,\n",
       "         -9.75072384e-02,  7.69071043e-01, -2.74246931e-02,\n",
       "          5.03755569e-01, -5.40047772e-02, -1.41679153e-01,\n",
       "          5.93397975e-01],\n",
       "        [-1.58516303e-01, -2.01209769e-01, -3.78505170e-01,\n",
       "         -3.12907785e-01, -7.93645009e-02,  7.63768181e-02,\n",
       "         -4.24651057e-01, -8.46328288e-02,  1.17951557e-02,\n",
       "         -4.20826972e-02,  1.00522742e-01, -1.37264624e-01,\n",
       "          1.15545854e-01,  8.49287957e-02,  1.23058788e-01,\n",
       "         -1.70798793e-01,  5.44929095e-02,  1.26724929e-01,\n",
       "          3.51987891e-02, -1.87033653e-01,  2.70275362e-02,\n",
       "         -4.89609167e-02, -9.09181610e-02,  1.46511486e-02,\n",
       "          1.24683604e-01, -1.02032863e-01, -1.26748323e-01,\n",
       "         -1.61689743e-01, -1.09603539e-01,  1.61480606e-01,\n",
       "         -1.98162287e-01,  1.74598113e-01,  1.05717465e-01,\n",
       "         -3.23890299e-02, -2.02757329e-01, -4.91038486e-02,\n",
       "         -3.64761442e-01,  7.42655620e-02,  1.43442228e-01,\n",
       "         -7.04519153e-02, -8.45855400e-02,  1.08921997e-01,\n",
       "         -1.89696420e-02,  1.22216634e-01, -3.37444752e-01,\n",
       "          1.09430766e-02,  1.57980025e-01,  2.48756811e-01,\n",
       "         -1.79671291e-02,  1.98132902e-01, -5.22849895e-02,\n",
       "          8.30411762e-02,  2.22661376e-01, -3.05132151e-01,\n",
       "         -4.77069281e-02, -9.40291733e-02,  9.75018814e-02,\n",
       "          5.32403588e-03, -1.83576822e-01, -3.49771947e-01,\n",
       "         -1.29883081e-01, -8.50093961e-02, -5.65439686e-02,\n",
       "         -2.09394500e-01],\n",
       "        [ 1.12196915e-01, -2.01177314e-01,  1.09588012e-01,\n",
       "          1.77056417e-02,  5.72392493e-02, -3.08441967e-01,\n",
       "         -3.16474617e-01, -2.28787124e-01, -6.28836870e-01,\n",
       "         -5.39136410e-01,  1.42517775e-01, -1.59661239e-03,\n",
       "         -1.06112206e+00, -3.12333703e-01, -1.84928924e-01,\n",
       "         -3.26911092e-01,  8.50724950e-02,  2.40448356e-01,\n",
       "         -1.32421285e-01, -1.23241968e-01, -8.77517685e-02,\n",
       "         -1.29187748e-01, -4.45504189e-02, -2.01941088e-01,\n",
       "          3.50914925e-01,  4.38419253e-01,  1.43145785e-01,\n",
       "          1.00782581e-01,  3.04918736e-01, -4.41750698e-02,\n",
       "         -1.59736052e-01, -2.50656575e-01,  2.94012845e-01,\n",
       "         -9.39164869e-03,  2.75374919e-01,  1.17867827e-01,\n",
       "          1.54894188e-01, -6.88631773e-01, -7.07023680e-01,\n",
       "         -1.00780189e+00,  7.03604221e-01, -5.89796677e-02,\n",
       "          1.36180669e-01,  1.50834069e-01, -1.10083684e-01,\n",
       "          5.67612588e-01,  1.89997882e-01,  5.58707595e-01,\n",
       "          5.40701330e-01,  8.51125177e-03, -1.03373691e-01,\n",
       "         -1.89770788e-01,  2.12442845e-01,  1.71612367e-01,\n",
       "          1.03017256e-01, -2.58486509e-01,  1.82703473e-02,\n",
       "         -3.08079243e-01,  2.43947841e-03, -2.91494727e-01,\n",
       "          4.39002782e-01,  1.41182169e-01, -2.41308048e-01,\n",
       "          7.10621238e-01],\n",
       "        [-1.23418219e-01, -2.82721072e-01, -1.62921414e-01,\n",
       "          1.68197528e-01, -2.21389756e-02,  1.47303730e-01,\n",
       "         -2.99712658e-01, -8.25053230e-02,  1.32596446e-02,\n",
       "         -3.58252376e-01,  1.14717726e-02, -2.81646192e-01,\n",
       "         -7.10197762e-02,  2.57023543e-01, -8.31221696e-03,\n",
       "         -1.85915112e-01, -4.16456833e-02,  2.67713279e-01,\n",
       "         -6.82379380e-02,  8.41692165e-02,  1.12222292e-01,\n",
       "         -4.02188748e-02,  1.04777440e-01,  3.46232690e-02,\n",
       "          7.67919049e-02,  1.48270741e-01,  8.91745761e-02,\n",
       "         -2.83691324e-02, -4.59518023e-02, -4.07820269e-02,\n",
       "         -3.04418266e-01, -2.44435430e-01,  3.19812410e-02,\n",
       "          6.92687705e-02, -1.55347930e-02, -2.13689640e-01,\n",
       "         -1.36026680e-01,  6.23736344e-02,  5.35231456e-02,\n",
       "         -4.88727130e-02,  1.89869329e-01,  1.55143023e-01,\n",
       "          4.71161716e-02,  5.11906929e-02, -2.93594629e-01,\n",
       "         -4.10429649e-02, -3.31715606e-02,  4.41403329e-01,\n",
       "         -1.41666740e-01,  6.43332601e-02,  2.46899843e-01,\n",
       "         -1.98002100e-01, -1.95710227e-01, -2.68090904e-01,\n",
       "          1.29217897e-02, -3.40210050e-01,  1.43259764e-01,\n",
       "         -2.22896993e-01,  4.88191210e-02, -3.71791184e-01,\n",
       "          7.38645764e-03, -9.05563030e-03, -5.41821457e-02,\n",
       "          4.11880948e-02],\n",
       "        [ 2.01754704e-01, -9.13913175e-02, -1.58346910e-02,\n",
       "          2.14485556e-01, -1.47838220e-01, -2.73564011e-01,\n",
       "          1.33330878e-02, -1.78584427e-01,  3.63159657e-01,\n",
       "         -1.57061011e-01, -7.54399002e-02, -6.80723563e-02,\n",
       "          2.68976837e-01, -2.03521982e-01,  4.15644087e-02,\n",
       "          1.70133695e-01, -2.41133958e-01, -1.20533422e-01,\n",
       "          2.75769711e-01, -3.59849095e-01, -1.05169758e-01,\n",
       "         -4.90978062e-01, -2.53531814e-01,  1.61265284e-01,\n",
       "         -5.52981734e-01,  2.37263814e-01, -2.86691844e-01,\n",
       "         -6.40827343e-02,  2.29673292e-02,  1.16575293e-01,\n",
       "          9.80419219e-02,  6.90521747e-02, -3.54702234e-01,\n",
       "          2.90191352e-01, -3.86328816e-01, -2.69572437e-01,\n",
       "         -1.71876624e-02,  2.99139112e-01,  2.48872533e-01,\n",
       "          3.35191637e-01, -2.73684859e-01, -2.15147417e-02,\n",
       "         -1.13448143e-01, -3.70799229e-02, -6.50724322e-02,\n",
       "         -3.26519489e-01, -3.46934468e-01, -1.48023576e-01,\n",
       "         -1.48699716e-01, -1.91622894e-04, -2.54295226e-02,\n",
       "         -1.34324715e-01,  1.30426675e-01, -1.94069043e-01,\n",
       "         -4.23570573e-01, -1.78054601e-01,  2.43007973e-01,\n",
       "          5.84515072e-02, -5.29394031e-01,  1.76249921e-01,\n",
       "         -3.05302322e-01, -2.55728792e-02,  6.72939792e-02,\n",
       "         -2.51973182e-01],\n",
       "        [ 1.21419899e-01, -2.19247609e-01, -2.08295919e-02,\n",
       "         -3.43790501e-02, -2.31073797e-01,  9.77721661e-02,\n",
       "         -1.41116828e-01,  1.11619376e-01, -1.15694785e-02,\n",
       "          1.75252840e-01,  5.19685075e-02,  1.49261788e-01,\n",
       "         -3.96216894e-03, -1.82855353e-01, -1.22123152e-01,\n",
       "          1.22909918e-01, -5.30195907e-02, -6.64612651e-02,\n",
       "          2.39214018e-01,  2.16547340e-01,  2.82618366e-02,\n",
       "         -4.10247296e-02, -1.99697033e-01,  6.39357194e-02,\n",
       "          4.86127026e-02,  1.35893419e-01, -9.93942395e-02,\n",
       "         -2.92132217e-02, -9.48150922e-03,  1.99911207e-01,\n",
       "          8.39911699e-02,  1.28821746e-01, -2.87563711e-01,\n",
       "          3.93677726e-02, -1.63941048e-02, -2.24680211e-02,\n",
       "         -5.88099249e-02,  7.10427687e-02, -1.11387432e-01,\n",
       "         -4.82331276e-01, -4.46873084e-02, -7.10648075e-02,\n",
       "          5.39438725e-02, -1.11100331e-01, -3.69336396e-01,\n",
       "          5.74907139e-02, -7.81207383e-02, -1.76252976e-01,\n",
       "         -2.92227715e-02, -4.21062298e-02,  1.80485751e-02,\n",
       "          2.06085965e-01,  8.82034376e-02,  4.88775112e-02,\n",
       "          1.34494707e-01,  1.90035284e-01,  2.47319162e-01,\n",
       "         -2.80297976e-02,  5.93705140e-02,  2.21950486e-01,\n",
       "          3.94630656e-02,  7.61341602e-02, -6.15630597e-02,\n",
       "         -1.06916735e-02],\n",
       "        [-2.19932228e-01,  1.25205711e-01,  9.57453921e-02,\n",
       "          8.04296732e-02,  1.62135884e-01, -8.02320316e-02,\n",
       "         -7.38416612e-03,  2.36879423e-01, -2.30404705e-01,\n",
       "         -8.80638361e-02, -2.64872015e-01, -7.33848661e-02,\n",
       "          2.28971586e-01, -1.22213736e-02,  1.57459676e-01,\n",
       "         -5.48937880e-02,  2.84846034e-02, -2.25562025e-02,\n",
       "          1.78080231e-01,  1.37951553e-01,  2.69707948e-01,\n",
       "         -8.18606317e-02, -5.22543192e-02,  1.63207233e-01,\n",
       "         -9.47683826e-02,  5.00545390e-02,  2.06402391e-01,\n",
       "         -1.94592565e-01, -2.77756322e-02, -6.26387596e-02,\n",
       "          2.93974072e-01, -3.07289302e-01, -2.34070793e-01,\n",
       "          1.24413736e-01,  1.29244784e-02, -1.90253988e-01,\n",
       "          1.33149669e-01,  1.25696763e-01, -2.37499520e-01,\n",
       "         -2.91508287e-01, -5.73296100e-02,  2.24834323e-01,\n",
       "          1.73919518e-02, -2.45883033e-01, -3.39911073e-01,\n",
       "          6.67898683e-03,  8.36845413e-02,  2.46725734e-02,\n",
       "         -1.07727490e-01, -1.83094740e-01,  1.28117025e-01,\n",
       "         -1.92882270e-02, -2.64852792e-01, -2.12101206e-01,\n",
       "          9.51867104e-02,  1.11000001e-01,  1.76987261e-01,\n",
       "         -8.95899981e-02, -6.14866205e-02,  1.09930731e-01,\n",
       "          4.69968505e-02, -1.27657861e-01, -1.91712603e-02,\n",
       "         -2.17040293e-02],\n",
       "        [-5.88762462e-02, -2.89464407e-02, -3.00021440e-01,\n",
       "          1.22639909e-01,  2.36388911e-02,  1.66631877e-01,\n",
       "         -2.53238827e-01,  1.95137873e-01,  3.76324356e-02,\n",
       "         -1.36353508e-01, -1.50287941e-01, -1.41453505e-01,\n",
       "         -1.77749153e-02, -2.98654228e-01, -5.08307219e-01,\n",
       "         -1.38034850e-01,  1.91666972e-04,  7.55347833e-02,\n",
       "          1.42867073e-01,  1.00609601e-01,  1.31982058e-01,\n",
       "          4.53554653e-02, -2.73983628e-01, -2.32320994e-01,\n",
       "         -1.28618451e-02,  6.18844703e-02, -4.70407605e-02,\n",
       "          1.33670960e-02, -2.93384939e-02, -1.81882381e-01,\n",
       "         -2.76093155e-01, -3.87109369e-01, -2.93113142e-01,\n",
       "         -5.56166247e-02,  6.95521981e-02, -4.88488853e-01,\n",
       "          6.86076880e-02,  1.11925602e-03,  1.87974125e-01,\n",
       "         -3.58733684e-02, -1.70966815e-02,  1.61240418e-02,\n",
       "         -9.47927237e-02,  1.32147074e-01, -1.05135113e-01,\n",
       "          4.76699043e-03, -1.24801986e-01,  1.17598318e-01,\n",
       "         -1.40565023e-01,  9.89715010e-02, -5.50084598e-02,\n",
       "         -1.07396156e-01, -1.89446479e-01,  8.93462300e-02,\n",
       "         -3.46185379e-02,  5.11005195e-03, -9.60538909e-02,\n",
       "          1.26465447e-02,  8.56371783e-03,  6.37326241e-02,\n",
       "          2.77444683e-02, -2.31437355e-01, -4.92243260e-01,\n",
       "         -5.01517355e-02],\n",
       "        [ 1.96294919e-01, -1.79853782e-01, -3.28237191e-03,\n",
       "          3.95460278e-02,  7.92083070e-02, -8.91869590e-02,\n",
       "         -4.01434124e-01, -8.40486586e-02,  1.14444480e-03,\n",
       "         -1.18507661e-01, -7.07578659e-02, -1.11092329e-02,\n",
       "         -5.72761111e-02, -3.00409317e-01,  1.49771860e-02,\n",
       "          4.03888188e-02, -1.10381156e-01,  7.75693133e-02,\n",
       "          7.44150719e-03, -1.90879539e-01, -8.32421854e-02,\n",
       "          1.03497818e-01, -3.08214903e-01,  4.35487367e-02,\n",
       "          1.37813091e-01, -1.97140992e-01, -2.63320237e-01,\n",
       "          2.18004689e-01, -6.64417967e-02,  6.25152066e-02,\n",
       "          2.02538460e-01, -6.80885836e-02, -4.59131449e-02,\n",
       "         -7.28670415e-03, -3.22274655e-01, -3.92151922e-01,\n",
       "         -1.42353445e-01, -2.78456416e-03, -1.36807680e-01,\n",
       "         -2.14188248e-02, -7.39376247e-02, -5.00795245e-02,\n",
       "          2.09305242e-01,  1.07850909e-01, -4.92357686e-02,\n",
       "         -1.89005639e-02,  8.11452866e-02,  1.27602756e-01,\n",
       "          2.26314515e-01,  1.20387241e-01, -1.65194765e-01,\n",
       "         -1.14900526e-02, -5.25399595e-02, -2.73516387e-01,\n",
       "         -4.73301232e-01, -1.09682478e-01, -1.10621609e-01,\n",
       "          3.95564511e-02,  1.25379432e-02, -1.71039164e-01,\n",
       "         -3.31545055e-01,  2.98526287e-02,  1.97395951e-01,\n",
       "          2.74872363e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.03752368, -0.15894979, -0.14663526, -0.14164002, -0.15177424,\n",
       "        -0.09521478, -0.20910646, -0.1683745 , -0.2673171 , -0.22375797,\n",
       "        -0.15315442, -0.15258245, -0.25056538, -0.03149085,  0.0114972 ,\n",
       "        -0.10941978, -0.03170777,  0.1133693 , -0.32199228, -0.0753179 ,\n",
       "        -0.1322252 , -0.1100212 , -0.10284039, -0.15978706, -0.00771002,\n",
       "         0.09533563, -0.1706095 ,  0.05412257,  0.12990536, -0.24532038,\n",
       "        -0.04824938, -0.0576825 , -0.11657854,  0.02405947,  0.03086608,\n",
       "        -0.22303683, -0.11698319, -0.21958774, -0.18954939, -0.1620168 ,\n",
       "         0.1306469 ,  0.03819382,  0.01684826,  0.07410721, -0.11675336,\n",
       "         0.09716232,  0.00861458,  0.2733968 ,  0.11492833, -0.03054303,\n",
       "         0.18184096, -0.2563796 , -0.00128977, -0.01289609, -0.09085774,\n",
       "        -0.1799569 ,  0.01149736, -0.10980958, -0.01109844, -0.18236868,\n",
       "         0.17358632,  0.03875711,  0.03631736,  0.10003679], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[-0.11643245, -0.19506928,  0.00666626, ..., -0.22957489,\n",
       "         -0.03652822, -0.15616201],\n",
       "        [-0.06585509, -0.08007796, -0.25566307, ..., -0.09830179,\n",
       "          0.12279648,  0.01384139],\n",
       "        [-0.05639707,  0.08682703, -0.05571791, ...,  0.09995656,\n",
       "         -0.02246165, -0.19839412],\n",
       "        ...,\n",
       "        [-0.19948885, -0.15096238, -0.04819959, ..., -0.13006881,\n",
       "         -0.11389831, -0.15553865],\n",
       "        [-0.18391356, -0.07687863, -0.21989155, ..., -0.14418195,\n",
       "         -0.19296595,  0.07564012],\n",
       "        [-0.16201481,  0.19372134, -0.30091757, ..., -0.03399932,\n",
       "         -0.2321779 ,  0.03762311]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.08681732, -0.07899202, -0.19840632, -0.02728941, -0.03129759,\n",
       "        -0.0245747 , -0.19360085, -0.12159294, -0.07651396, -0.1736887 ,\n",
       "        -0.2423856 , -0.13640189, -0.09666876, -0.00252273, -0.15931892,\n",
       "        -0.09317644, -0.12148219, -0.12358897, -0.11841232, -0.06296531,\n",
       "        -0.18472564, -0.02816815, -0.08981376, -0.1651806 , -0.03650397,\n",
       "        -0.10278788, -0.05322117, -0.2447677 , -0.07125395, -0.15469086,\n",
       "        -0.10360922, -0.01803176, -0.08737788, -0.17528282, -0.17154753,\n",
       "        -0.10290707, -0.09636479,  0.01178936, -0.12619965,  0.02950378,\n",
       "        -0.12145168,  0.02201528, -0.12441029, -0.09394982, -0.0784827 ,\n",
       "        -0.15277913, -0.12619409,  0.0141417 ,  0.02845354, -0.16407296,\n",
       "        -0.13556346, -0.08089544, -0.15794812, -0.0840661 , -0.11689792,\n",
       "        -0.1518162 , -0.12128124,  0.36600858, -0.11956917,  0.35279286,\n",
       "        -0.14864375, -0.16226222, -0.21089438, -0.19754785], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(64, 1) dtype=float32, numpy=\n",
       " array([[-0.13074377],\n",
       "        [ 0.00135128],\n",
       "        [ 0.12867375],\n",
       "        [-0.08239928],\n",
       "        [-0.01457304],\n",
       "        [-0.21198952],\n",
       "        [ 0.08090779],\n",
       "        [ 0.24952172],\n",
       "        [-0.02071374],\n",
       "        [ 0.11258499],\n",
       "        [ 0.06259018],\n",
       "        [-0.03377033],\n",
       "        [ 0.00358805],\n",
       "        [ 0.00864597],\n",
       "        [ 0.00061606],\n",
       "        [-0.04509078],\n",
       "        [-0.00804162],\n",
       "        [ 0.18063639],\n",
       "        [-0.03324347],\n",
       "        [ 0.05082871],\n",
       "        [ 0.01692517],\n",
       "        [ 0.03166969],\n",
       "        [ 0.00741454],\n",
       "        [ 0.01400338],\n",
       "        [ 0.06421588],\n",
       "        [-0.18592252],\n",
       "        [-0.07801052],\n",
       "        [ 0.03484543],\n",
       "        [-0.0061742 ],\n",
       "        [ 0.11751829],\n",
       "        [ 0.03104756],\n",
       "        [-0.12894514],\n",
       "        [-0.12154393],\n",
       "        [ 0.07262167],\n",
       "        [ 0.12194426],\n",
       "        [ 0.03898755],\n",
       "        [-0.00238514],\n",
       "        [-0.06809378],\n",
       "        [-0.16293697],\n",
       "        [-0.02935606],\n",
       "        [ 0.21093516],\n",
       "        [-0.10577124],\n",
       "        [-0.00745454],\n",
       "        [ 0.00262874],\n",
       "        [ 0.00413557],\n",
       "        [ 0.09282822],\n",
       "        [ 0.14198029],\n",
       "        [-0.00175968],\n",
       "        [-0.01146932],\n",
       "        [-0.19346808],\n",
       "        [-0.17366351],\n",
       "        [ 0.01337102],\n",
       "        [ 0.10974567],\n",
       "        [ 0.03417754],\n",
       "        [-0.15641907],\n",
       "        [ 0.06732958],\n",
       "        [ 0.03789586],\n",
       "        [-0.05609873],\n",
       "        [ 0.00628212],\n",
       "        [-0.04339981],\n",
       "        [ 0.0099262 ],\n",
       "        [ 0.24339618],\n",
       "        [ 0.09573893],\n",
       "        [ 0.05043773]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([-1.152857], dtype=float32)>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer is 2 and shape is (14, 64)\n",
      "layer is 3 and shape is (64,)\n",
      "layer is 4 and shape is (64, 64)\n",
      "layer is 5 and shape is (64,)\n",
      "layer is 6 and shape is (64, 1)\n",
      "layer is 7 and shape is (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('layer is {} and shape is {}'.format(i+2,j.numpy().shape)) for i,j in enumerate(model.trainable_variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables[2].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Layer in module tensorflow.python.keras.engine.base_layer:\n",
      "\n",
      "class Layer(tensorflow.python.training.tracking.base.Trackable)\n",
      " |  Base layer class.\n",
      " |  \n",
      " |  This is the class from which all layers inherit.\n",
      " |  \n",
      " |  A layer is a class implementing common neural networks operations, such\n",
      " |  as convolution, batch norm, etc. These operations require managing weights,\n",
      " |  losses, updates, and inter-layer connectivity.\n",
      " |  \n",
      " |  Users will just instantiate a layer and then treat it as a callable.\n",
      " |  \n",
      " |  We recommend that descendants of `Layer` implement the following methods:\n",
      " |  \n",
      " |  * `__init__()`: Save configuration in member variables\n",
      " |  * `build()`: Called once from `__call__`, when we know the shapes of inputs\n",
      " |    and `dtype`. Should have the calls to `add_weight()`, and then\n",
      " |    call the super's `build()` (which sets `self.built = True`, which is\n",
      " |    nice in case the user wants to call `build()` manually before the\n",
      " |    first `__call__`).\n",
      " |  * `call()`: Called in `__call__` after making sure `build()` has been called\n",
      " |    once. Should actually perform the logic of applying the layer to the\n",
      " |    input tensors (which should be passed in as the first argument).\n",
      " |  \n",
      " |  Arguments:\n",
      " |    trainable: Boolean, whether the layer's variables should be trainable.\n",
      " |    name: String name of the layer.\n",
      " |    dtype: Default dtype of the layer's weights (default of `None` means use the\n",
      " |      type of the first input).\n",
      " |    dynamic: Set this to `True` if your layer should only be run eagerly, and\n",
      " |      should not be used to generate a static computation graph.\n",
      " |      This would be the case for a Tree-RNN or a recursive network,\n",
      " |      for example, or generally for any layer that manipulates tensors\n",
      " |      using Python control flow. If `False`, we assume that the layer can\n",
      " |      safely be used to generate a static computation graph.\n",
      " |  \n",
      " |  Read-only properties:\n",
      " |    name: The name of the layer (string).\n",
      " |    dtype: Default dtype of the layer's weights (default of `None` means use the\n",
      " |      type of the first input).\n",
      " |    updates: List of update ops of this layer.\n",
      " |    losses: List of losses added by this layer.\n",
      " |    trainable_weights: List of variables to be included in backprop.\n",
      " |    non_trainable_weights: List of variables that should not be\n",
      " |      included in backprop.\n",
      " |    weights: The concatenation of the lists trainable_weights and\n",
      " |      non_trainable_weights (in this order).\n",
      " |  \n",
      " |  Mutable properties:\n",
      " |    trainable: Whether the layer should be trained (boolean).\n",
      " |    input_spec: Optional (list of) `InputSpec` object(s) specifying the\n",
      " |      constraints on inputs that can be accepted by the layer.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Layer\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Note that `add_loss` is not supported when executing eagerly. Instead,\n",
      " |      variable regularizers may be added through `add_variable`. Activity\n",
      " |      regularization is not supported directly (but such losses may be returned\n",
      " |      from `Layer.call()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |          Other types of input are ignored.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `model.add_metric(BinaryAccuracy(name='acc')(y_true,\n",
      " |          y_pred))`. If aggregation='mean', the given metric tensor will be\n",
      " |          sample-wise reduced using `mean` function. eg, `model.add_metric(\n",
      " |          tf.reduce_sum(outputs), name='output_mean', aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops.\n",
      " |        inputs: If anything other than None is passed, it signals the updates\n",
      " |          are conditional on some of the layer's inputs,\n",
      " |          and thus they should only be run where these inputs are available.\n",
      " |          This is the case for BatchNormalization updates, for instance.\n",
      " |          If None, the updates will be taken into account unconditionally,\n",
      " |          and you are responsible for making sure that any dependency they might\n",
      " |          have is available at runtime.\n",
      " |          A step counter might fall into this category.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: initializer instance (callable).\n",
      " |        regularizer: regularizer instance (callable).\n",
      " |        trainable: whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      " |          Note, if the current variable scope is marked as non-trainable\n",
      " |          then this parameter is ignored and any added variables are also\n",
      " |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      " |          `synchronization` is set to `ON_READ`.\n",
      " |        constraint: constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Apply the layer on a input.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs, **kwargs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.layers.Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining custom layer by inheriting keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    # Define the constructor\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "    # Define the build function to add the weights\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[input_shape[-1],\n",
    "                                           self.num_outputs])\n",
    "    # Define the forward pass\n",
    "    def call(self, input):\n",
    "        matmul = tf.matmul(input, self.kernel)\n",
    "        return tf.nn.relu(matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'my_dense_layer/kernel:0' shape=(3, 10) dtype=float32, numpy=\n",
      "array([[ 0.5871947 ,  0.2719518 , -0.5207156 ,  0.5307281 ,  0.515087  ,\n",
      "        -0.56889236,  0.1849286 ,  0.05857337, -0.4218513 , -0.05166322],\n",
      "       [ 0.42664838, -0.10283864,  0.09976953, -0.32675567, -0.19674423,\n",
      "         0.23550111,  0.20437837,  0.057262  ,  0.04569757,  0.27271807],\n",
      "       [ 0.19364613, -0.06766313, -0.19314322,  0.15209782, -0.11772496,\n",
      "        -0.255608  , -0.6316012 ,  0.21347821, -0.64492285,  0.27364182]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the layer with 10 output units\n",
    "layer = MyDenseLayer(10)\n",
    "# Supply the input shape\n",
    "layer(tf.random.uniform((10,3)))\n",
    "# Display the trainable parameters of the layer\n",
    "print(layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]], shape=(1, 2, 3, 3), dtype=float32)\n",
      "['resnet_identity_block/conv2d/kernel:0', 'resnet_identity_block/conv2d/bias:0', 'resnet_identity_block/batch_normalization_v2/gamma:0', 'resnet_identity_block/batch_normalization_v2/beta:0', 'resnet_identity_block/conv2d_1/kernel:0', 'resnet_identity_block/conv2d_1/bias:0', 'resnet_identity_block/batch_normalization_v2_1/gamma:0', 'resnet_identity_block/batch_normalization_v2_1/beta:0', 'resnet_identity_block/conv2d_2/kernel:0', 'resnet_identity_block/conv2d_2/bias:0', 'resnet_identity_block/batch_normalization_v2_2/gamma:0', 'resnet_identity_block/batch_normalization_v2_2/beta:0']\n"
     ]
    }
   ],
   "source": [
    "block = ResnetIdentityBlock(1, [1, 2, 3])\n",
    "print(block(tf.zeros([1, 2, 3, 3])))\n",
    "print([x.name for x in block.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility in model training\n",
    "- TensorFlow can use automatic differentiation to compute the gradients of the loss function with respect to model parameters. \n",
    "- tf.GradientTape creates a tape within a context which is used by TensorFlow to keep track of the gradients recorded from each computation in that tape. \n",
    "- To understand this, let's define a model in a more low-level way by extending the tf.keras.Model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyCustomModel,self).__init__()\n",
    "        self.do1=tf.keras.layers.Dropout(rate=0.2,input_shape=((14,)))\n",
    "        self.fc1=tf.keras.layers.Dense(units=64,activation='relu')\n",
    "        self.do2=tf.keras.layers.Dropout(rate=0.2)\n",
    "        self.fc2=tf.keras.layers.Dense(units=64,activation='relu')\n",
    "        self.do3=tf.keras.layers.Dropout(rate=0.2)\n",
    "        self.fc3=tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "    def call(x):\n",
    "        x=self.do1(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.do2(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.do3(x)\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__=CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc=tf.keras.metrics.BinaryAccuracy(name='train_acc')\n",
    "test_loss=tf.keras.metrics.Mean(name='test_loss')\n",
    "test_acc=tf.keras.metrics.BinaryAccuracy(name='test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test=X_train.astype(np.float32),X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train,Y_test=Y_train.astype(np.float32),Y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train,Y_test=Y_train.reshape([-1,1]),Y_test.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=tf.data.Dataset.from_tensor_slices((X_train,Y_train)).batch(64)\n",
    "test_ds=tf.data.Dataset.from_tensor_slices((X_test,Y_test)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model_train(features,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds=model__(features)\n",
    "        loss=loss_func(labels,preds)\n",
    "        grads=tape.gradient(loss,model__.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads,model__.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_acc(labels,preds)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model_val(features,labels):\n",
    "    preds=model__(features)\n",
    "    loss=loss_func(labels,preds)\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_acc(labels,preds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 1, train loss is 7557220.500000,train_acc is 71.37046813964844, val_loss is 0.000000 and val_acc is tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "epoch is 2, train loss is 7378438.000000,train_acc is 71.5301742553711, val_loss is 0.000000 and val_acc is tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "epoch is 3, train loss is 7275412.500000,train_acc is 71.65166473388672, val_loss is 0.000000 and val_acc is tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "epoch is 4, train loss is 7042067.500000,train_acc is 71.83634185791016, val_loss is 0.000000 and val_acc is tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "epoch is 5, train loss is 6856099.500000,train_acc is 71.96324157714844, val_loss is 0.000000 and val_acc is tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for ep in range(5):\n",
    "    for feat, label in train_ds:\n",
    "        model_train(feat,label)\n",
    "    for t_feat, t_label in test_ds:\n",
    "        model_val(t_feat,t_label)\n",
    "    templ='epoch is {}, train loss is {:3f},train_acc is {}, val_loss is {:3f} and val_acc is'\n",
    "    print(templ.format(ep+1,train_loss.result()*10e5,train_acc.result()*100,test_loss.result()*10e5),test_acc.result()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examples from tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_datasets.image.mnist.MNIST at 0x7f9f80204d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist=tfds.builder('mnist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist (11.06 MiB) to /home/abzooba/tensorflow_datasets/mnist/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd750a9269c4c229f3ec85c14de8967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Completed...', max=1, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bf05ec9643425d96828980faac56b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Size...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c084848d3085435bb799c3ba62eaade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Extraction completed...', max=1, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ef72594df8444ba16441e7752afce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed29a7ddfffa42f3b9c5144f2e2de58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 14:38:22.081953 140324234954560 deprecation.py:323] From /home/abzooba/.local/lib/python3.6/site-packages/tensorflow_datasets/core/file_format_adapter.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589b05a30d274779ad4a06e568be68b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7443c5a3f209429d9be9ea77265911bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa6d90aeda84c2e852d887752fc373d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbf6134ed8e445e95a035c63cb8b78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe3602785a7447787d48375c10bb8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f37399fa0604856b6735563f7904cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2dfedf2703412884054f56b14657f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd6ea9989a54ff6b966ef5d6d3007da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543b110e74f84d6eac8198b3625ecd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b65acd35afe4856b33401f6e089667a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9880c158dc455f8b7093dbcfd830ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53094c8276e84bac8d73def1554773f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ac722a5f964e03a38f9727159c3549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5737f1650e32471fbe70cb17fbb647fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01598e9a061411ca09aa43a9737250d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5bc509323f40c991c3857818aa4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602d8cbb2d6450ebefd412f731f556f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b08988e51714639a794f883946ed333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3a786bb994398890a7af903efbbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066002bab1f64fb7aec32fc4943c95c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4b8d42516441438abb0a8bc4f205c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f5668381c4f38ad7e14718d96c830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622d1a2c8ad841c79d3af5a5e0669d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b84383c87c47f59da0d9fd40935630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=10000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[1mDataset mnist downloaded and prepared to /home/abzooba/tensorflow_datasets/mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mnist.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,test_ds=mnist.as_dataset(split=[tfds.Split.TRAIN,tfds.Split.TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in train_ds:\n",
    "    image, label = features[\"image\"], features[\"label\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 28, 28, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e5a5ee470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0].numpy().reshape((28,28)),cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Make a directory to keep the training logs\n",
    "os.mkdir(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the callback\n",
    "logdir = \"logs\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs  TF_2_training.ipynb  TF_2_training.slides.html\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dropout(rate=0.2, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 10682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10682), started 0:21:21 ago. (Use '!kill 10682' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6dcc427e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6dcc427a20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/\n",
    "model.fit(X_train, Y_train,\n",
    "         validation_data=(X_test, Y_test),\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

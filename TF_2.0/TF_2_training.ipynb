{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_data=pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must be written at code start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample snippet showing tf.function and eager execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8938249 , 1.1993818 , 0.8473539 , 1.1591743 , 0.4158116 ],\n",
       "       [0.91332257, 1.2487595 , 0.9243051 , 1.1471107 , 0.53097093]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the forward pass\n",
    "@tf.function\n",
    "def single_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "# Generate random data drawn from a uniform distribution\n",
    "x = tf.random.uniform((2, 3))\n",
    "y = tf.random.uniform((3, 5))\n",
    "\n",
    "# by default eager execution is enabled\n",
    "# can be disabled by using  tf.compat.v1.disable_eager_execution()\n",
    "single_layer(x, y).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable([[3.0]])\n",
    "w.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=99, shape=(1, 1), dtype=float32, numpy=array([[2.1972246]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    loss = tf.math.log(w * w)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.6666667]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "grad = tape.gradient(loss, w)\n",
    "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that you did not have to create any sessions or placeholders to run the function single_layer(). \n",
    "- This is one of the nifty features of tf.function. Behind the hood, it does all the necessary optimizations so that your code runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification using tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"]\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
    "                    header=None,\n",
    "                    names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import qgrid\n",
    "# qgrid.show_grid(data,show_toolbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode\n",
    "le = LabelEncoder()\n",
    "data = data.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2671</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2926</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14086</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15336</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19355</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  Occupation  \\\n",
       "0   22          7    2671          9            12              4           1   \n",
       "1   33          6    2926          9            12              2           4   \n",
       "2   21          4   14086         11             8              0           6   \n",
       "3   36          4   15336          1             6              2           6   \n",
       "4   11          4   19355          9            12              2          10   \n",
       "\n",
       "   Relationship  Race  Gender  CapitalGain  CapitalLoss  HoursPerWeek  \\\n",
       "0             1     4       1           25            0            39   \n",
       "1             0     4       1            0            0            12   \n",
       "2             1     4       1            0            0            39   \n",
       "3             0     2       1            0            0            39   \n",
       "4             5     2       0            0            0            39   \n",
       "\n",
       "   NativeCountry  Income  \n",
       "0             39       0  \n",
       "1             39       0  \n",
       "2             39       0  \n",
       "3             39       0  \n",
       "4              5       0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate data features & convert into NumPy arrays\n",
    "X = data.iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2671</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2926</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14086</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15336</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19355</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1      2   3   4  5   6  7  8  9  10  11  12  13\n",
       "0  22  7   2671   9  12  4   1  1  4  1  25   0  39  39\n",
       "1  33  6   2926   9  12  2   4  0  4  1   0   0  12  39\n",
       "2  21  4  14086  11   8  0   6  1  4  1   0   0  39  39\n",
       "3  36  4  15336   1   6  2   6  0  2  1   0   0  39  39\n",
       "4  11  4  19355   9  12  2  10  5  2  0   0   0  39   5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Income'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dropout(rate=0.2, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the output probabilities\n",
    "# out_probs = model(X_train.astype(np.float32), training=True)\n",
    "# print(out_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above we have done only the forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable v2 functionality anytime, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 15:50:59.672461 139623060518720 deprecation.py:323] From /home/abzooba/Desktop/all_venv/tf_2/tf_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/5\n",
      "26048/26048 [==============================] - 1s 34us/sample - loss: 8.0175 - accuracy: 0.4223 - val_loss: 3.6554 - val_accuracy: 0.7623\n",
      "Epoch 2/5\n",
      "26048/26048 [==============================] - 1s 27us/sample - loss: 3.5139 - accuracy: 0.7266 - val_loss: 3.6579 - val_accuracy: 0.7623\n",
      "Epoch 3/5\n",
      "26048/26048 [==============================] - 1s 25us/sample - loss: 3.3240 - accuracy: 0.7364 - val_loss: 3.6575 - val_accuracy: 0.7623\n",
      "Epoch 4/5\n",
      "26048/26048 [==============================] - 1s 27us/sample - loss: 3.2206 - accuracy: 0.7457 - val_loss: 3.6575 - val_accuracy: 0.7623\n",
      "Epoch 5/5\n",
      "26048/26048 [==============================] - 1s 33us/sample - loss: 3.1911 - accuracy: 0.7473 - val_loss: 3.6574 - val_accuracy: 0.7623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc224f4f60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable parameters in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(14, 64) dtype=float32, numpy=\n",
       " array([[-1.02864601e-01, -2.96717137e-01,  3.38823497e-02,\n",
       "         -1.22029908e-01,  7.83774257e-02,  2.53891647e-01,\n",
       "          1.90069616e-01, -2.13950500e-01,  1.67218253e-01,\n",
       "         -7.84098078e-03,  9.23313349e-02, -6.68321736e-03,\n",
       "          1.95580617e-01, -2.51073003e-01, -5.52640557e-02,\n",
       "         -4.82294187e-02,  9.78343859e-02,  2.76492797e-02,\n",
       "          2.79025018e-01, -2.75526464e-01, -1.11299947e-01,\n",
       "          7.12905750e-02, -2.54581845e-03,  1.22474931e-01,\n",
       "          4.49687727e-02,  1.80996910e-01, -1.36218295e-01,\n",
       "         -7.71358833e-02, -7.03014880e-02,  9.14896131e-02,\n",
       "         -2.33908698e-01, -8.34711269e-02, -2.96957135e-01,\n",
       "          2.04175174e-01, -2.93462276e-01,  9.15092826e-02,\n",
       "          6.53404295e-02,  2.10800529e-01,  1.72781721e-01,\n",
       "          1.86774582e-01, -1.49937555e-01, -1.91494584e-01,\n",
       "          1.07325576e-01, -2.63218105e-01, -2.56204128e-01,\n",
       "         -7.55416378e-02, -3.73307220e-03,  1.02404421e-02,\n",
       "          1.75120831e-02, -1.60093620e-01,  2.13432476e-01,\n",
       "          7.46875852e-02, -2.68546194e-01, -2.50474751e-01,\n",
       "          2.09489372e-02,  3.23474593e-02, -2.64621079e-01,\n",
       "          6.08034655e-02, -2.72962362e-01, -1.25206977e-01,\n",
       "         -1.69866607e-01, -1.60472885e-01,  1.06596597e-01,\n",
       "         -1.08490773e-01],\n",
       "        [-2.74778754e-02,  1.36476129e-01,  2.63882428e-02,\n",
       "         -1.73615739e-01,  9.50095728e-02,  2.07117438e-01,\n",
       "          5.74168712e-02,  9.38913375e-02, -5.75489439e-02,\n",
       "          2.48686932e-02,  2.27875307e-01,  1.84737191e-01,\n",
       "         -1.97604164e-01, -2.26196855e-01,  1.17059782e-01,\n",
       "         -8.88878480e-02,  6.47209659e-02,  5.60541973e-02,\n",
       "          3.42690572e-02,  1.54393032e-01,  1.31769493e-01,\n",
       "          2.22239435e-01,  2.11344108e-01, -1.10748254e-01,\n",
       "         -1.03918284e-01, -5.33736609e-02, -4.95834947e-02,\n",
       "          3.67411152e-02, -8.30490887e-02, -1.22687876e-01,\n",
       "          1.50345221e-01,  2.30987117e-01, -1.61442105e-02,\n",
       "          1.75522000e-01,  1.52644768e-01,  8.13561082e-02,\n",
       "         -1.57342970e-01, -1.45747080e-01,  5.95897203e-03,\n",
       "         -2.40128711e-01,  8.51432085e-02,  4.04429100e-02,\n",
       "          1.53421253e-01,  1.86285481e-01, -1.98827423e-02,\n",
       "          1.37775943e-01, -1.44506618e-01,  8.95453468e-02,\n",
       "         -2.17024963e-02,  2.72461742e-01, -1.91866487e-01,\n",
       "         -2.08131224e-01, -1.70531690e-01,  1.04641579e-01,\n",
       "          2.44454533e-01, -1.40967384e-01, -2.23168463e-01,\n",
       "         -8.21275115e-02,  4.85620238e-02, -2.08961159e-01,\n",
       "          3.88803519e-02, -2.23763853e-01,  2.07608908e-01,\n",
       "         -1.86460074e-02],\n",
       "        [-1.97759315e-01,  2.16108829e-01, -1.75602213e-01,\n",
       "         -1.47464275e-01, -1.58381671e-01, -2.10046083e-01,\n",
       "          2.62486517e-01,  2.24364195e-02, -2.19565630e-01,\n",
       "         -1.98383033e-01, -8.02913234e-02, -1.18493870e-01,\n",
       "          2.74220929e-02,  1.87285751e-01,  2.14438692e-01,\n",
       "         -1.48446620e-01, -2.07308352e-01,  6.64324239e-02,\n",
       "          2.05641165e-02,  2.60843337e-01, -2.21646801e-01,\n",
       "          1.00241758e-01, -5.69717549e-02, -2.31090859e-01,\n",
       "         -1.47906750e-01,  4.76116240e-02, -2.08606839e-01,\n",
       "          5.06836586e-02, -1.70408383e-01, -1.76639512e-01,\n",
       "          7.98805431e-02,  5.68359680e-02,  1.58258274e-01,\n",
       "         -3.09849833e-03, -1.42094880e-01, -2.09544247e-04,\n",
       "          1.69500664e-01,  2.14551792e-01,  1.32862121e-01,\n",
       "          3.53765748e-02, -8.77820775e-02,  2.17038840e-01,\n",
       "         -2.49242947e-01, -8.83332640e-02, -2.40970969e-01,\n",
       "         -8.89424533e-02, -9.99622867e-02, -1.57848433e-01,\n",
       "          1.65770333e-02,  2.31358603e-01,  1.93685457e-01,\n",
       "          2.35579565e-01,  2.35761628e-01,  1.51203973e-02,\n",
       "         -1.17585644e-01,  1.69688672e-01,  1.38201445e-01,\n",
       "          1.93490744e-01,  2.09496260e-01, -7.78954150e-03,\n",
       "         -1.24177210e-01, -1.67304829e-01, -1.11199528e-01,\n",
       "         -1.93729475e-01],\n",
       "        [ 2.67011881e-01, -6.95957616e-02, -7.98977315e-02,\n",
       "          1.02803171e-01, -1.97791025e-01,  2.08155587e-01,\n",
       "         -7.35460296e-02, -6.05529845e-02, -1.18169010e-01,\n",
       "          2.16102347e-01,  2.11777136e-01, -1.74384579e-01,\n",
       "         -1.85838297e-01, -2.11139590e-01,  1.34300962e-01,\n",
       "         -2.34976739e-01, -2.52755731e-01, -1.46782696e-01,\n",
       "         -2.44205490e-01, -3.40814851e-02,  1.47335187e-01,\n",
       "          7.64298290e-02, -5.62522113e-02,  1.09581865e-01,\n",
       "         -2.64193565e-01,  9.62477848e-02, -7.23156035e-02,\n",
       "         -1.03329112e-04, -1.54695272e-01,  9.46410596e-02,\n",
       "         -2.40123030e-02, -2.14300036e-01,  1.73055045e-02,\n",
       "         -1.13336228e-01,  9.97278243e-02,  1.02145694e-01,\n",
       "         -5.25986440e-02,  1.30219147e-01,  1.36389047e-01,\n",
       "          1.94282368e-01,  2.06821725e-01,  2.45369092e-01,\n",
       "          1.02308795e-01,  2.20297668e-02,  6.44477010e-02,\n",
       "         -1.37560204e-01,  1.71209238e-02, -9.58933607e-02,\n",
       "         -9.29812789e-02,  5.87390177e-02, -1.33812174e-01,\n",
       "         -1.03947967e-01,  2.12987006e-01,  1.73493251e-01,\n",
       "         -4.36218828e-02, -1.42034009e-01, -2.70402879e-01,\n",
       "          2.13114142e-01,  7.72103071e-02,  2.26727188e-01,\n",
       "          2.87953615e-01,  2.45101064e-01,  1.90029502e-01,\n",
       "         -2.84446239e-01],\n",
       "        [ 1.15133844e-01,  8.87106583e-02, -1.59566239e-01,\n",
       "         -1.08308256e-01, -1.21922322e-01, -2.12672859e-01,\n",
       "          9.37082469e-02,  4.12513036e-03,  1.12813637e-01,\n",
       "          2.53105700e-01,  2.69322302e-02, -6.04957156e-02,\n",
       "         -1.73299536e-01, -1.16302995e-02, -9.41336155e-02,\n",
       "          2.05027223e-01,  1.37514129e-01,  1.16536468e-02,\n",
       "         -2.52807468e-01, -1.21511877e-01,  2.81648766e-02,\n",
       "         -2.17451587e-01,  8.05962831e-02, -6.50326982e-02,\n",
       "          2.60686159e-01, -1.95558786e-01,  1.50141463e-01,\n",
       "         -2.56821048e-02, -3.89444232e-02, -1.54684633e-01,\n",
       "         -1.25151664e-01, -8.33826438e-02,  2.06857100e-01,\n",
       "         -1.42230764e-01,  7.50399157e-02,  2.41079569e-01,\n",
       "         -1.92390352e-01,  1.67891160e-01, -3.15690339e-02,\n",
       "         -1.56311899e-01,  2.51430005e-01,  1.49770290e-01,\n",
       "         -8.89549926e-02,  1.56425297e-01, -2.05845773e-01,\n",
       "         -2.14038819e-01, -8.17431509e-02, -2.73601592e-01,\n",
       "         -2.38485932e-01, -9.15119201e-02,  5.46129718e-02,\n",
       "         -2.55177349e-01,  7.37885833e-02, -1.89088732e-01,\n",
       "         -1.36420550e-02,  2.05238074e-01,  2.50052631e-01,\n",
       "         -2.43982868e-05,  1.96364313e-01, -2.08621368e-01,\n",
       "          1.75097495e-01,  2.10931331e-01, -3.81997414e-02,\n",
       "         -1.84204891e-01],\n",
       "        [-2.72001475e-01,  1.54418707e-01,  1.20489419e-01,\n",
       "          2.11762965e-01, -1.68179020e-01,  1.86625689e-01,\n",
       "          1.93611577e-01,  2.63781965e-01, -1.75684512e-01,\n",
       "         -2.85345346e-01,  1.41666844e-01, -1.96085423e-01,\n",
       "         -1.33724036e-02,  3.64416279e-02, -1.22210190e-01,\n",
       "          2.05556229e-01,  2.77417243e-01,  6.38829963e-03,\n",
       "          5.48538975e-02, -1.12040982e-01,  8.69875997e-02,\n",
       "          5.55497445e-02,  2.49031976e-01, -2.47818395e-01,\n",
       "         -1.59765497e-01, -2.08913788e-01,  3.98725830e-03,\n",
       "          2.00432122e-01,  3.15903202e-02,  1.65727481e-01,\n",
       "          1.63388669e-01,  1.54325422e-02, -1.26586780e-01,\n",
       "          1.22518122e-01, -2.71125793e-01, -2.65792757e-01,\n",
       "          1.49606720e-01,  3.04511562e-02,  2.52990931e-01,\n",
       "         -1.84093446e-01, -9.19019431e-02,  1.81424320e-01,\n",
       "          1.51221171e-01, -1.09637626e-01, -1.96102578e-02,\n",
       "         -2.51056105e-01,  1.51794165e-01, -3.32393423e-02,\n",
       "          2.07243115e-02,  1.69454813e-01,  8.16405118e-02,\n",
       "         -3.50487530e-02,  7.39318877e-02,  1.63697690e-01,\n",
       "          1.46768630e-01,  1.62881985e-01, -2.09924921e-01,\n",
       "         -2.69119531e-01, -2.67795742e-01,  1.87528834e-01,\n",
       "         -7.71377608e-02, -4.42520417e-02, -2.33280614e-01,\n",
       "         -1.71865635e-02],\n",
       "        [ 2.53199011e-01,  1.32903546e-01, -3.20184305e-02,\n",
       "         -1.89458225e-02,  2.82932997e-01, -2.56918639e-01,\n",
       "          1.53627411e-01,  1.43658787e-01,  1.16404109e-01,\n",
       "          1.82554238e-02, -1.42582268e-01, -2.36546278e-01,\n",
       "          1.20158292e-01, -9.45580378e-02,  9.62129384e-02,\n",
       "          3.00716963e-02,  2.61428714e-01, -4.91614528e-02,\n",
       "          1.44812092e-01,  2.31730297e-01, -1.88263968e-01,\n",
       "          1.55783147e-01, -8.53523612e-02,  7.81618357e-02,\n",
       "          2.46587127e-01,  9.71704721e-03, -1.48005217e-01,\n",
       "         -1.72959253e-01, -1.56444147e-01,  2.47273251e-01,\n",
       "         -2.18993217e-01, -3.71820927e-02, -9.50910002e-02,\n",
       "         -4.55426164e-02, -1.77354425e-01, -2.09103048e-01,\n",
       "          1.65986866e-01, -1.43480197e-01, -1.70220643e-01,\n",
       "         -1.16880320e-01,  1.05668508e-01,  1.94675803e-01,\n",
       "         -2.37341464e-01,  1.12077400e-01,  1.42171979e-01,\n",
       "          7.87327439e-02, -8.89687054e-03, -2.52046049e-01,\n",
       "          2.64012784e-01, -2.53635317e-01,  1.50740728e-01,\n",
       "         -1.29212178e-02, -6.21558689e-02,  1.03283249e-01,\n",
       "          2.81896461e-02, -2.46416360e-01,  2.23289162e-01,\n",
       "         -3.03698957e-01, -8.93469453e-02, -2.42450699e-01,\n",
       "         -2.05365583e-01,  1.97288364e-01,  1.76214091e-02,\n",
       "         -1.14620171e-01],\n",
       "        [ 2.73327917e-01,  1.06428780e-01,  1.67176381e-01,\n",
       "         -5.16784154e-02, -2.74408191e-01,  9.27040577e-02,\n",
       "          4.82409932e-02, -2.60868724e-02,  1.21634200e-01,\n",
       "          2.05963567e-01,  1.63973495e-01, -2.57483155e-01,\n",
       "          2.73022830e-01, -1.07380815e-01, -2.07141027e-01,\n",
       "          1.50234208e-01, -1.14009087e-03, -1.28563866e-01,\n",
       "          2.14114755e-01, -1.65708303e-01, -1.32905498e-01,\n",
       "         -2.70625174e-01,  1.46618009e-01,  2.19387650e-01,\n",
       "         -1.14869922e-01, -1.48386359e-01, -2.26581201e-01,\n",
       "          1.84387162e-01,  2.70377308e-01, -2.51361281e-01,\n",
       "          2.04501182e-01, -8.28098282e-02, -2.39068821e-01,\n",
       "         -2.93964874e-02, -1.64104849e-01, -2.96248227e-01,\n",
       "         -8.59223157e-02, -2.95821100e-01,  5.06485328e-02,\n",
       "         -2.03547999e-01,  9.51347724e-02,  2.13531200e-02,\n",
       "          2.47260436e-01,  2.19882399e-01, -2.63088271e-02,\n",
       "         -6.67509735e-02, -1.56382974e-02, -2.52935529e-01,\n",
       "         -2.12392002e-01, -5.47763593e-02, -5.61500266e-02,\n",
       "          2.21559420e-01, -3.81840393e-03, -2.95608431e-01,\n",
       "         -3.76052707e-02, -1.55131832e-01,  1.74014747e-01,\n",
       "         -7.83284679e-02,  1.68117985e-01, -1.08184591e-01,\n",
       "         -7.86177441e-02,  2.51447141e-01,  2.51598060e-01,\n",
       "          6.09861724e-02],\n",
       "        [-2.55403548e-01,  3.36614661e-02, -2.74117351e-01,\n",
       "          3.15060057e-02,  2.72430629e-01,  2.12653354e-01,\n",
       "         -1.53724343e-01,  1.20353267e-01, -7.60467574e-02,\n",
       "          3.77275608e-02,  1.59977168e-01,  4.31776010e-02,\n",
       "          1.80161238e-01,  6.80857152e-02,  2.23638937e-01,\n",
       "         -3.15596117e-03,  2.75339514e-01,  1.24154143e-01,\n",
       "         -8.64821151e-02,  1.96567878e-01,  3.95158902e-02,\n",
       "          1.31986827e-01, -2.47005537e-01,  6.18349807e-03,\n",
       "         -1.54903740e-01, -1.93010807e-01,  1.97208136e-01,\n",
       "         -8.32082555e-02,  4.60698791e-02, -2.49590836e-02,\n",
       "         -1.60651803e-01, -1.93570420e-01,  1.77688047e-01,\n",
       "         -1.39208436e-01,  1.45589903e-01, -6.99350610e-02,\n",
       "         -5.80387190e-02,  1.64026543e-01,  2.94066697e-01,\n",
       "         -4.00712863e-02,  1.70988172e-01, -2.33556613e-01,\n",
       "         -1.50501907e-01, -1.59077242e-01, -2.05865249e-01,\n",
       "          5.89883588e-02,  1.98351771e-01, -1.94393784e-01,\n",
       "         -5.30314185e-02,  1.92431241e-01, -2.34578490e-01,\n",
       "         -2.24737391e-01, -1.38752893e-01, -1.65733859e-01,\n",
       "          2.29447950e-02, -2.61651397e-01, -2.78814565e-02,\n",
       "         -2.95453310e-01, -9.71807465e-02,  1.57304630e-01,\n",
       "          1.32499620e-01,  2.73943562e-02,  2.14688763e-01,\n",
       "          2.36524910e-01],\n",
       "        [ 9.57408100e-02, -2.70376448e-03, -3.68930101e-02,\n",
       "         -2.42823660e-01,  1.02602266e-01,  1.26691431e-01,\n",
       "          1.95622563e-01, -2.27255076e-01, -2.69132733e-01,\n",
       "          1.66925952e-01,  2.59220749e-01,  2.84799747e-03,\n",
       "          1.01991646e-01, -5.34683093e-02,  3.40933017e-02,\n",
       "         -1.96509689e-01,  1.11853994e-01, -1.22878015e-01,\n",
       "          6.36216775e-02,  2.38046914e-01, -2.06160635e-01,\n",
       "          7.91388005e-03,  1.98892370e-01, -2.85882084e-03,\n",
       "         -4.76152338e-02,  1.22172222e-01, -2.08851472e-01,\n",
       "         -1.73342720e-01, -3.59577797e-02,  1.01055190e-01,\n",
       "          8.79433975e-02, -1.41465031e-02,  1.99820548e-02,\n",
       "         -2.43344039e-01,  2.04896137e-01,  6.46518096e-02,\n",
       "          1.27938211e-01, -3.00136060e-01, -8.11970606e-02,\n",
       "          1.06386736e-01, -8.25552270e-02,  2.05037236e-01,\n",
       "          5.34777194e-02,  1.27359450e-01, -2.03867555e-01,\n",
       "         -2.87995599e-02, -8.52052867e-02, -2.34337613e-01,\n",
       "         -2.45776504e-01, -2.40354165e-01,  3.91316973e-02,\n",
       "          8.78588930e-02, -1.39593944e-01, -2.64520168e-01,\n",
       "         -9.43102092e-02,  1.97207302e-01, -3.91824692e-02,\n",
       "          4.06970456e-02, -1.76509097e-01, -1.98975354e-01,\n",
       "          2.35212758e-01, -1.61779851e-01,  1.05598733e-01,\n",
       "         -7.74652287e-02],\n",
       "        [-9.20598805e-02, -2.57805616e-01, -1.60190016e-01,\n",
       "          8.38438869e-02,  1.80633709e-01, -3.73257026e-02,\n",
       "          3.23575698e-02, -2.03896925e-01, -1.81564495e-01,\n",
       "          1.20889939e-01, -1.18414007e-01,  1.99398454e-02,\n",
       "         -1.15189478e-01, -1.92868248e-01, -2.33298525e-01,\n",
       "          1.53160542e-01,  5.63482696e-04,  2.42688432e-02,\n",
       "         -2.59166211e-01,  1.68827042e-01,  1.72177777e-01,\n",
       "          1.93968549e-01,  2.58617606e-02, -7.84096941e-02,\n",
       "         -2.94457406e-01,  1.34536967e-01, -1.65861785e-01,\n",
       "          2.09980473e-01, -1.26087770e-01, -2.57464409e-01,\n",
       "          7.56523535e-02, -1.98519945e-01, -1.17019951e-01,\n",
       "          1.62242010e-01, -4.99924161e-02,  1.04147352e-01,\n",
       "         -2.39317551e-01,  9.24751312e-02, -2.36249954e-01,\n",
       "          2.19028145e-01,  1.05896972e-01, -2.00789973e-01,\n",
       "         -1.12155907e-01, -6.53251028e-03,  9.05284360e-02,\n",
       "         -9.19567794e-02,  7.52811283e-02,  2.43999779e-01,\n",
       "         -5.42484447e-02,  3.71668488e-03, -1.24943927e-01,\n",
       "         -1.07790560e-01, -4.94092703e-02, -1.24387972e-01,\n",
       "          1.99519113e-01,  6.30192831e-02, -1.26707911e-01,\n",
       "         -1.03912465e-01, -1.40554190e-01, -1.11672223e-01,\n",
       "          1.54745832e-01, -1.67905688e-02, -1.88366398e-01,\n",
       "          1.26908332e-01],\n",
       "        [ 1.50934622e-01, -3.85684520e-02,  1.08938843e-01,\n",
       "          1.23460457e-01, -2.27697313e-01, -2.15457782e-01,\n",
       "         -2.24005416e-01,  1.44980937e-01,  1.61950037e-01,\n",
       "         -2.25508451e-01,  5.38315512e-02,  1.57205775e-01,\n",
       "          3.12335249e-02,  9.50254221e-03,  1.51776507e-01,\n",
       "          2.00713933e-01,  9.57856700e-02,  1.45595580e-01,\n",
       "          2.44041398e-01,  1.23252459e-01, -2.27811843e-01,\n",
       "         -2.37089202e-01, -2.21453935e-01,  2.16003850e-01,\n",
       "          2.80202657e-01, -1.04129754e-01, -1.30546719e-01,\n",
       "         -2.49237016e-01, -1.89807892e-01,  2.69246548e-01,\n",
       "          1.24585733e-01, -1.16514705e-01, -2.36630470e-01,\n",
       "         -1.15524799e-01, -9.92060527e-02, -4.89174277e-02,\n",
       "         -4.38723564e-02, -2.56497085e-01, -8.84066448e-02,\n",
       "         -1.89352423e-01,  1.36253223e-01,  1.80002034e-01,\n",
       "         -1.38112068e-01, -1.58452183e-01,  1.80671081e-01,\n",
       "          1.20829001e-01,  4.50171158e-03,  2.59478778e-01,\n",
       "         -1.75360322e-01,  2.39275426e-01,  4.18868065e-02,\n",
       "         -8.98774248e-03,  3.58863883e-02,  1.87896565e-01,\n",
       "         -1.62317336e-01,  1.58871144e-01,  1.81434602e-02,\n",
       "          1.59448907e-01, -2.76165847e-02, -6.62943125e-02,\n",
       "         -2.29771942e-01, -1.63631439e-01, -6.29555201e-03,\n",
       "         -1.92970231e-01],\n",
       "        [-2.64332563e-01,  1.62083253e-01,  8.36836323e-02,\n",
       "          1.89093545e-01, -5.35599589e-02, -2.28585705e-01,\n",
       "         -2.85684168e-01,  1.93487838e-01, -8.98228660e-02,\n",
       "         -1.80369496e-01, -2.24866271e-01,  2.27821037e-01,\n",
       "          5.58527820e-02, -1.60910040e-01, -4.94176634e-02,\n",
       "          1.52607918e-01, -1.38819531e-01,  1.69820130e-01,\n",
       "         -8.83906558e-02,  2.75852419e-02,  1.08822191e-03,\n",
       "         -3.89542691e-02, -1.86946526e-01, -2.82957166e-01,\n",
       "          5.17141186e-02, -1.01510458e-01, -9.61690247e-02,\n",
       "         -5.10138273e-02,  8.70537311e-02,  1.75300334e-02,\n",
       "          1.20681264e-02, -8.68976414e-02,  1.54829606e-01,\n",
       "          2.90942520e-01,  2.46795848e-01, -1.18671529e-01,\n",
       "          1.22558862e-01,  7.92672783e-02,  1.76895261e-01,\n",
       "          1.02697186e-01, -6.17402084e-02,  7.15599284e-02,\n",
       "          1.06601249e-02, -1.68720007e-01,  2.42334023e-01,\n",
       "         -7.16145933e-02,  1.28621295e-01, -9.43936780e-02,\n",
       "          6.43050531e-03, -7.31881417e-04, -1.69110060e-01,\n",
       "          5.12328558e-02,  7.50191733e-02,  1.49922788e-01,\n",
       "          2.21396670e-01,  1.28175095e-01,  2.00503424e-01,\n",
       "          2.06951171e-01, -2.31147647e-01,  2.33531579e-01,\n",
       "          2.36742809e-01, -1.39030263e-01, -2.06629142e-01,\n",
       "          8.93665180e-02],\n",
       "        [-6.32664561e-02,  1.58714369e-01,  2.30650023e-01,\n",
       "         -6.06910661e-02, -1.21133119e-01, -1.50042832e-01,\n",
       "         -2.68604606e-01, -2.70816714e-01,  2.43460909e-02,\n",
       "         -8.75206739e-02, -1.55669764e-01, -6.96666613e-02,\n",
       "         -5.74279986e-02, -5.71836345e-02, -1.98530868e-01,\n",
       "          6.84135109e-02,  2.52539068e-01,  1.30966842e-01,\n",
       "         -9.32187140e-02,  1.14860430e-01, -2.08180845e-01,\n",
       "         -3.32768001e-02,  2.51935571e-01,  3.74303833e-02,\n",
       "          1.39079001e-02, -1.29156098e-01, -2.71823019e-01,\n",
       "          1.80466503e-01, -5.45638846e-03,  1.15272477e-01,\n",
       "          1.93382815e-01, -9.11189914e-02,  1.48854166e-01,\n",
       "         -5.78783080e-02,  1.84947088e-01, -9.71551165e-02,\n",
       "         -1.67368740e-01,  1.73509926e-01, -2.55492121e-01,\n",
       "         -1.36755452e-01,  7.13488609e-02, -6.51797876e-02,\n",
       "          6.06916808e-02,  8.23688731e-02,  2.12947756e-01,\n",
       "         -9.66183022e-02, -3.59724648e-02, -7.77872875e-02,\n",
       "         -1.14508517e-01,  1.04175813e-01,  7.63637200e-03,\n",
       "          1.20058998e-01, -2.09994376e-01,  1.08648956e-01,\n",
       "         -1.40333563e-01,  1.83174506e-01,  2.45907158e-01,\n",
       "         -8.97444934e-02, -2.71938115e-01,  1.73842430e-01,\n",
       "          2.87961401e-03,  2.99969912e-01, -1.13553882e-01,\n",
       "         -2.00427473e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.00509393, -0.03881143, -0.03605639,  0.00772028,  0.01394497,\n",
       "         0.00855195, -0.02079365,  0.02615708, -0.03107642, -0.0134523 ,\n",
       "        -0.0018195 , -0.01189474, -0.01855527,  0.01652856,  0.016989  ,\n",
       "        -0.02180329,  0.00710179, -0.06575328,  0.00892984, -0.01496157,\n",
       "        -0.0303192 , -0.04961045, -0.0143922 , -0.0034278 , -0.01900418,\n",
       "        -0.01650363,  0.01788008, -0.02898336, -0.01656959,  0.00218162,\n",
       "        -0.03210696, -0.0109574 , -0.02123368,  0.03844802, -0.01532323,\n",
       "        -0.03028284,  0.00506235, -0.05842084,  0.02303164, -0.02342253,\n",
       "        -0.02069633,  0.02048924,  0.04047491, -0.01640013,  0.00056707,\n",
       "         0.00677171, -0.02055785, -0.00689453,  0.01239201,  0.0001289 ,\n",
       "        -0.04076796, -0.03086468,  0.00921857, -0.01264247,  0.00138154,\n",
       "        -0.05184427, -0.01825333, -0.03485041,  0.0093881 , -0.01660613,\n",
       "         0.01452377,  0.04364126, -0.01116535, -0.0267062 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[ 0.1691948 ,  0.00591902,  0.1857623 , ..., -0.0312468 ,\n",
       "          0.06409394, -0.1280228 ],\n",
       "        [-0.12480964, -0.10199452,  0.06515382, ...,  0.18027583,\n",
       "         -0.09236889, -0.21257311],\n",
       "        [ 0.1838297 ,  0.10505988,  0.0103104 , ...,  0.10814918,\n",
       "          0.03596106, -0.1169681 ],\n",
       "        ...,\n",
       "        [-0.08961111,  0.00274306, -0.06039335, ..., -0.23007736,\n",
       "          0.19041432,  0.21241723],\n",
       "        [ 0.2012055 ,  0.10814006, -0.17221834, ...,  0.08604751,\n",
       "          0.01913065, -0.07086658],\n",
       "        [ 0.16558278, -0.14180249, -0.22252989, ..., -0.1187349 ,\n",
       "         -0.07036567, -0.16002458]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-8.61036032e-03, -3.13721113e-02, -1.58130564e-02, -1.05705475e-02,\n",
       "         1.60122067e-02,  1.24548199e-02,  8.39625020e-03,  1.05162757e-02,\n",
       "        -1.65687804e-03,  1.25648789e-02, -2.17815377e-02, -1.48398280e-02,\n",
       "        -1.72786806e-02, -3.87841016e-02, -2.38846391e-02,  2.40129908e-03,\n",
       "        -7.23295985e-03, -9.27664340e-03,  9.85791348e-03, -3.64140309e-02,\n",
       "         1.19123388e-05, -1.11423470e-02,  3.53902914e-02, -1.43531784e-02,\n",
       "        -2.33887341e-02,  6.96909614e-03, -8.22305214e-03,  2.05732230e-03,\n",
       "        -3.19038890e-02,  8.31428170e-03, -1.47369904e-02, -2.95970496e-02,\n",
       "        -2.76442859e-02, -1.84091851e-02, -3.50987576e-02,  1.48410266e-02,\n",
       "        -2.25549955e-02, -2.40305047e-02, -3.58545221e-02,  3.92114036e-02,\n",
       "        -3.43880802e-02,  2.22637914e-02, -3.33305672e-02, -2.65572667e-02,\n",
       "        -5.95920300e-03, -2.17411071e-02, -2.43958533e-02,  7.29729421e-03,\n",
       "        -6.50048302e-03, -2.50814594e-02, -1.95228530e-03,  2.57774945e-02,\n",
       "         3.93225346e-03,  3.74072278e-03, -3.05319577e-03, -6.79921638e-03,\n",
       "        -2.32482832e-02,  9.20325704e-03, -1.92599483e-02,  1.46823125e-02,\n",
       "        -4.08924669e-02, -2.92965285e-02,  1.65265054e-02, -1.76828075e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(64, 1) dtype=float32, numpy=\n",
       " array([[-0.21724834],\n",
       "        [ 0.14597625],\n",
       "        [ 0.2280394 ],\n",
       "        [-0.14633478],\n",
       "        [-0.05354783],\n",
       "        [-0.14463472],\n",
       "        [-0.12074769],\n",
       "        [-0.1677769 ],\n",
       "        [ 0.21870005],\n",
       "        [-0.059643  ],\n",
       "        [ 0.09847035],\n",
       "        [-0.24483973],\n",
       "        [-0.25834155],\n",
       "        [ 0.07862148],\n",
       "        [ 0.10709282],\n",
       "        [-0.12476751],\n",
       "        [ 0.25795442],\n",
       "        [-0.00030889],\n",
       "        [-0.19418286],\n",
       "        [ 0.20812133],\n",
       "        [-0.19247887],\n",
       "        [ 0.03978543],\n",
       "        [-0.20494139],\n",
       "        [ 0.10072583],\n",
       "        [ 0.08418538],\n",
       "        [-0.1130612 ],\n",
       "        [ 0.13668387],\n",
       "        [-0.12082429],\n",
       "        [ 0.27522945],\n",
       "        [-0.27400047],\n",
       "        [ 0.0721588 ],\n",
       "        [ 0.26707187],\n",
       "        [ 0.17039588],\n",
       "        [-0.24099627],\n",
       "        [ 0.10031368],\n",
       "        [-0.25042564],\n",
       "        [ 0.15126233],\n",
       "        [ 0.09779759],\n",
       "        [ 0.03772141],\n",
       "        [-0.09162136],\n",
       "        [ 0.27071965],\n",
       "        [-0.02481055],\n",
       "        [ 0.2098816 ],\n",
       "        [ 0.20390241],\n",
       "        [-0.25051188],\n",
       "        [ 0.04492321],\n",
       "        [ 0.22270486],\n",
       "        [-0.02468172],\n",
       "        [-0.12498319],\n",
       "        [ 0.07683799],\n",
       "        [-0.2223804 ],\n",
       "        [-0.05776741],\n",
       "        [-0.23998629],\n",
       "        [-0.18014967],\n",
       "        [ 0.2549656 ],\n",
       "        [ 0.12273991],\n",
       "        [ 0.02685551],\n",
       "        [-0.06304932],\n",
       "        [ 0.14461556],\n",
       "        [-0.14106089],\n",
       "        [ 0.24116987],\n",
       "        [ 0.15490867],\n",
       "        [-0.02348123],\n",
       "        [ 0.13873939]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([-0.02425565], dtype=float32)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer is 2 and shape is (14, 64)\n",
      "layer is 3 and shape is (64,)\n",
      "layer is 4 and shape is (64, 64)\n",
      "layer is 5 and shape is (64,)\n",
      "layer is 6 and shape is (64, 1)\n",
      "layer is 7 and shape is (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('layer is {} and shape is {}'.format(i+2,j.numpy().shape)) for i,j in enumerate(model.trainable_variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables[2].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Layer in module tensorflow.python.keras.engine.base_layer:\n",
      "\n",
      "class Layer(tensorflow.python.module.module.Module)\n",
      " |  Base layer class.\n",
      " |  \n",
      " |  This is the class from which all layers inherit.\n",
      " |  \n",
      " |  A layer is a class implementing common neural networks operations, such\n",
      " |  as convolution, batch norm, etc. These operations require managing weights,\n",
      " |  losses, updates, and inter-layer connectivity.\n",
      " |  \n",
      " |  Users will just instantiate a layer and then treat it as a callable.\n",
      " |  \n",
      " |  We recommend that descendants of `Layer` implement the following methods:\n",
      " |  \n",
      " |  * `__init__()`: Save configuration in member variables\n",
      " |  * `build()`: Called once from `__call__`, when we know the shapes of inputs\n",
      " |    and `dtype`. Should have the calls to `add_weight()`, and then\n",
      " |    call the super's `build()` (which sets `self.built = True`, which is\n",
      " |    nice in case the user wants to call `build()` manually before the\n",
      " |    first `__call__`).\n",
      " |  * `call()`: Called in `__call__` after making sure `build()` has been called\n",
      " |    once. Should actually perform the logic of applying the layer to the\n",
      " |    input tensors (which should be passed in as the first argument).\n",
      " |  \n",
      " |  Arguments:\n",
      " |    trainable: Boolean, whether the layer's variables should be trainable.\n",
      " |    name: String name of the layer.\n",
      " |    dtype: Default dtype of the layer's weights (default of `None` means use the\n",
      " |      type of the first input).\n",
      " |    dynamic: Set this to `True` if your layer should only be run eagerly, and\n",
      " |      should not be used to generate a static computation graph.\n",
      " |      This would be the case for a Tree-RNN or a recursive network,\n",
      " |      for example, or generally for any layer that manipulates tensors\n",
      " |      using Python control flow. If `False`, we assume that the layer can\n",
      " |      safely be used to generate a static computation graph.\n",
      " |  \n",
      " |  Read-only properties:\n",
      " |    name: The name of the layer (string).\n",
      " |    dtype: Default dtype of the layer's weights (default of `None` means use the\n",
      " |      type of the first input).\n",
      " |    updates: List of update ops of this layer.\n",
      " |    losses: List of losses added by this layer.\n",
      " |    trainable_weights: List of variables to be included in backprop.\n",
      " |    non_trainable_weights: List of variables that should not be\n",
      " |      included in backprop.\n",
      " |    weights: The concatenation of the lists trainable_weights and\n",
      " |      non_trainable_weights (in this order).\n",
      " |  \n",
      " |  Mutable properties:\n",
      " |    trainable: Whether the layer should be trained (boolean).\n",
      " |    input_spec: Optional (list of) `InputSpec` object(s) specifying the\n",
      " |      constraints on inputs that can be accepted by the layer.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: initializer instance (callable).\n",
      " |        regularizer: regularizer instance (callable).\n",
      " |        trainable: whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      " |          Note, if the current variable scope is marked as non-trainable\n",
      " |          then this parameter is ignored and any added variables are also\n",
      " |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      " |          `synchronization` is set to `ON_READ`.\n",
      " |        constraint: constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Apply the layer on a input.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs, **kwargs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.layers.Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining custom layer by inheriting keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    # Define the constructor\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "    # Define the build function to add the weights\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[input_shape[-1],\n",
    "                                           self.num_outputs])\n",
    "    # Define the forward pass\n",
    "    def call(self, input):\n",
    "        matmul = tf.matmul(input, self.kernel)\n",
    "        return tf.nn.relu(matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'my_dense_layer/kernel:0' shape=(3, 10) dtype=float32, numpy=\n",
      "array([[ 0.6753609 ,  0.5715753 ,  0.08455652, -0.2546943 ,  0.20394635,\n",
      "        -0.67781   , -0.5730437 ,  0.09110492, -0.3634712 ,  0.0729323 ],\n",
      "       [ 0.33773685, -0.470486  , -0.3512328 ,  0.6367016 ,  0.42137384,\n",
      "         0.45066023, -0.3701003 ,  0.6769986 , -0.00250977, -0.24597982],\n",
      "       [-0.01499194,  0.0102793 , -0.30980727,  0.59046996,  0.45194638,\n",
      "         0.10995913, -0.19059977, -0.38108614, -0.27666068,  0.03205425]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the layer with 10 output units\n",
    "layer = MyDenseLayer(10)\n",
    "# Supply the input shape\n",
    "layer(tf.random.uniform((10,3)))\n",
    "# Display the trainable parameters of the layer\n",
    "print(layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]], shape=(1, 2, 3, 3), dtype=float32)\n",
      "['resnet_identity_block/conv2d/kernel:0', 'resnet_identity_block/conv2d/bias:0', 'resnet_identity_block/batch_normalization/gamma:0', 'resnet_identity_block/batch_normalization/beta:0', 'resnet_identity_block/conv2d_1/kernel:0', 'resnet_identity_block/conv2d_1/bias:0', 'resnet_identity_block/batch_normalization_1/gamma:0', 'resnet_identity_block/batch_normalization_1/beta:0', 'resnet_identity_block/conv2d_2/kernel:0', 'resnet_identity_block/conv2d_2/bias:0', 'resnet_identity_block/batch_normalization_2/gamma:0', 'resnet_identity_block/batch_normalization_2/beta:0']\n"
     ]
    }
   ],
   "source": [
    "block = ResnetIdentityBlock(1, [1, 2, 3])\n",
    "print(block(tf.zeros([1, 2, 3, 3])))\n",
    "print([x.name for x in block.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility in model training\n",
    "- TensorFlow can use automatic differentiation to compute the gradients of the loss function with respect to model parameters. \n",
    "- tf.GradientTape creates a tape within a context which is used by TensorFlow to keep track of the gradients recorded from each computation in that tape. \n",
    "- To understand this, let's define a model in a more low-level way by extending the tf.keras.Model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.do1 = tf.keras.layers.Dropout(rate=0.2, input_shape=(14,))\n",
    "        self.fc1 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.do2 = tf.keras.layers.Dropout(rate=0.2)\n",
    "        self.fc2 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.do3 = tf.keras.layers.Dropout(rate=0.2)\n",
    "        self.out = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.do1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.do2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.do3(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__ = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy(name='train_acc')\n",
    "\n",
    "valid_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "valid_acc = tf.keras.metrics.BinaryAccuracy(name='valid_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.astype(np.float32), X_test.astype(np.float32)\n",
    "Y_train, Y_test = Y_train.astype(np.int64), Y_test.astype(np.int64)\n",
    "Y_train, Y_test = Y_train.reshape(-1, 1), Y_test.reshape(-1, 1)\n",
    "\n",
    "# Batches of 64\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model_train(features, labels):\n",
    "    # Define the GradientTape context\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the probabilities\n",
    "        predictions = model__(features)\n",
    "        # Calculate the loss\n",
    "        loss = loss_func(labels, predictions)\n",
    "    # Get the gradients\n",
    "    gradients = tape.gradient(loss, model__.trainable_variables)\n",
    "    # Update the weights\n",
    "    optimizer.apply_gradients(zip(gradients, model__.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_acc(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def model_validate(features, labels):\n",
    "    predictions = model__(features)\n",
    "    t_loss = loss_func(labels, predictions)\n",
    "\n",
    "    valid_loss(t_loss)\n",
    "    valid_acc(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 11.575511932373047, train_acc: 65.85150146484375, train_loss: 12.6371488571167, test_acc: 26.485490798950195\n",
      "Epoch 2, train_loss: 10.653752326965332, train_acc: 66.8400650024414, train_loss: 9.910782814025879, test_acc: 52.541072845458984\n",
      "Epoch 3, train_loss: 9.44233512878418, train_acc: 67.60211944580078, train_loss: 7.160177230834961, test_acc: 60.64281463623047\n",
      "Epoch 4, train_loss: 8.283982276916504, train_acc: 68.41407775878906, train_loss: 5.745025157928467, test_acc: 65.10440826416016\n",
      "Epoch 5, train_loss: 7.606526851654053, train_acc: 68.8060531616211, train_loss: 8.022541046142578, test_acc: 67.4128646850586\n",
      "Epoch 6, train_loss: 6.859410285949707, train_acc: 69.4487075805664, train_loss: 7.194324970245361, test_acc: 69.3331298828125\n",
      "Epoch 7, train_loss: 6.6042561531066895, train_acc: 69.56881713867188, train_loss: 6.502121448516846, test_acc: 70.78370666503906\n",
      "Epoch 8, train_loss: 6.252860069274902, train_acc: 69.81485748291016, train_loss: 5.848987579345703, test_acc: 71.84285736083984\n",
      "Epoch 9, train_loss: 6.019529342651367, train_acc: 69.98191833496094, train_loss: 5.325138092041016, test_acc: 72.26231384277344\n",
      "Epoch 10, train_loss: 5.897688865661621, train_acc: 70.03071594238281, train_loss: 4.927680492401123, test_acc: 72.95869445800781\n",
      "Epoch 11, train_loss: 5.662069797515869, train_acc: 70.27131652832031, train_loss: 5.347165584564209, test_acc: 73.42517852783203\n",
      "Epoch 12, train_loss: 5.493423938751221, train_acc: 70.40847778320312, train_loss: 5.039217472076416, test_acc: 73.93802642822266\n",
      "Epoch 13, train_loss: 5.259575843811035, train_acc: 70.58773040771484, train_loss: 4.716302394866943, test_acc: 73.99520111083984\n",
      "Epoch 14, train_loss: 5.135020732879639, train_acc: 70.70491027832031, train_loss: 4.618269920349121, test_acc: 74.30194854736328\n",
      "Epoch 15, train_loss: 5.03347110748291, train_acc: 70.80620574951172, train_loss: 4.699952125549316, test_acc: 71.65361785888672\n",
      "Epoch 16, train_loss: 4.909593105316162, train_acc: 70.92626953125, train_loss: 4.469253063201904, test_acc: 72.16049194335938\n",
      "Epoch 17, train_loss: 4.756868362426758, train_acc: 71.07398986816406, train_loss: 4.326814651489258, test_acc: 71.12200927734375\n",
      "Epoch 18, train_loss: 4.618510723114014, train_acc: 71.19804382324219, train_loss: 4.148308753967285, test_acc: 71.65583038330078\n",
      "Epoch 19, train_loss: 4.507261753082275, train_acc: 71.31651306152344, train_loss: 4.234096050262451, test_acc: 71.92093658447266\n",
      "Epoch 20, train_loss: 4.430539131164551, train_acc: 71.37073516845703, train_loss: 4.153955459594727, test_acc: 72.29694366455078\n",
      "Epoch 21, train_loss: 4.311377048492432, train_acc: 71.47628784179688, train_loss: 4.041092872619629, test_acc: 72.62397766113281\n",
      "Epoch 22, train_loss: 4.199994087219238, train_acc: 71.58026885986328, train_loss: 3.9053144454956055, test_acc: 72.95967102050781\n",
      "Epoch 23, train_loss: 4.090737819671631, train_acc: 71.68922424316406, train_loss: 3.77065110206604, test_acc: 73.30422973632812\n",
      "Epoch 24, train_loss: 3.989466905593872, train_acc: 71.80909729003906, train_loss: 3.7527453899383545, test_acc: 73.45565795898438\n",
      "Epoch 25, train_loss: 3.9182279109954834, train_acc: 71.87008666992188, train_loss: 3.656599760055542, test_acc: 73.6784896850586\n",
      "Epoch 26, train_loss: 3.84702467918396, train_acc: 71.93376922607422, train_loss: 3.5595500469207764, test_acc: 73.92198181152344\n",
      "Epoch 27, train_loss: 3.7639567852020264, train_acc: 72.02201843261719, train_loss: 3.6839563846588135, test_acc: 74.02403259277344\n",
      "Epoch 28, train_loss: 3.68434476852417, train_acc: 72.11988067626953, train_loss: 3.7217724323272705, test_acc: 72.59821319580078\n",
      "Epoch 29, train_loss: 3.610826015472412, train_acc: 72.20833587646484, train_loss: 3.630901336669922, test_acc: 72.33649444580078\n",
      "Epoch 30, train_loss: 3.5393261909484863, train_acc: 72.29781341552734, train_loss: 3.5633325576782227, test_acc: 72.51394653320312\n",
      "Epoch 31, train_loss: 3.4704577922821045, train_acc: 72.37667846679688, train_loss: 3.5333237648010254, test_acc: 72.66905212402344\n",
      "Epoch 32, train_loss: 3.400546073913574, train_acc: 72.45613861083984, train_loss: 3.492734909057617, test_acc: 72.84037780761719\n",
      "Epoch 33, train_loss: 3.332810878753662, train_acc: 72.54940032958984, train_loss: 3.4464352130889893, test_acc: 72.95897674560547\n",
      "Epoch 34, train_loss: 3.2768986225128174, train_acc: 72.61119842529297, train_loss: 3.3967297077178955, test_acc: 73.10762786865234\n",
      "Epoch 35, train_loss: 3.213261127471924, train_acc: 72.6987533569336, train_loss: 3.3173677921295166, test_acc: 73.31929779052734\n",
      "Epoch 36, train_loss: 3.153472423553467, train_acc: 72.74774932861328, train_loss: 3.2435169219970703, test_acc: 73.51579284667969\n",
      "Epoch 37, train_loss: 3.096740245819092, train_acc: 72.8169174194336, train_loss: 3.186215877532959, test_acc: 73.6921157836914\n",
      "Epoch 38, train_loss: 3.0394227504730225, train_acc: 72.8982162475586, train_loss: 3.1428427696228027, test_acc: 73.78239440917969\n",
      "Epoch 39, train_loss: 2.9993696212768555, train_acc: 72.93222045898438, train_loss: 3.0805718898773193, test_acc: 73.94599151611328\n",
      "Epoch 40, train_loss: 2.9466986656188965, train_acc: 73.01424407958984, train_loss: 3.0346851348876953, test_acc: 74.08683013916016\n",
      "Epoch 41, train_loss: 2.8962907791137695, train_acc: 73.093017578125, train_loss: 2.9876503944396973, test_acc: 74.17098236083984\n",
      "Epoch 42, train_loss: 2.847247362136841, train_acc: 73.1672134399414, train_loss: 2.934933662414551, test_acc: 74.29939270019531\n",
      "Epoch 43, train_loss: 2.80051851272583, train_acc: 73.23367309570312, train_loss: 2.899930000305176, test_acc: 74.35826110839844\n",
      "Epoch 44, train_loss: 2.7561700344085693, train_acc: 73.30418395996094, train_loss: 2.859882354736328, test_acc: 74.44900512695312\n",
      "Epoch 45, train_loss: 2.71293044090271, train_acc: 73.36609649658203, train_loss: 2.811414957046509, test_acc: 74.57666015625\n",
      "Epoch 46, train_loss: 2.672020435333252, train_acc: 73.42206573486328, train_loss: 2.7626044750213623, test_acc: 74.71846008300781\n",
      "Epoch 47, train_loss: 2.63028621673584, train_acc: 73.49394226074219, train_loss: 2.7156100273132324, test_acc: 74.85062408447266\n",
      "Epoch 48, train_loss: 2.591108798980713, train_acc: 73.56459045410156, train_loss: 2.6718063354492188, test_acc: 74.97280883789062\n",
      "Epoch 49, train_loss: 2.55178165435791, train_acc: 73.63971710205078, train_loss: 2.6292827129364014, test_acc: 75.09251403808594\n",
      "Epoch 50, train_loss: 2.5174694061279297, train_acc: 73.70154571533203, train_loss: 2.595705509185791, test_acc: 75.17979431152344\n",
      "Epoch 51, train_loss: 2.4845075607299805, train_acc: 73.75651550292969, train_loss: 2.567768096923828, test_acc: 75.24047088623047\n",
      "Epoch 52, train_loss: 2.4504880905151367, train_acc: 73.818603515625, train_loss: 2.52791166305542, test_acc: 75.35963439941406\n",
      "Epoch 53, train_loss: 2.415790319442749, train_acc: 73.88565826416016, train_loss: 2.4907569885253906, test_acc: 75.46764373779297\n",
      "Epoch 54, train_loss: 2.383925676345825, train_acc: 73.94113159179688, train_loss: 2.4551286697387695, test_acc: 75.57080078125\n",
      "Epoch 55, train_loss: 2.352553129196167, train_acc: 74.00282287597656, train_loss: 2.4256064891815186, test_acc: 75.6263656616211\n",
      "Epoch 56, train_loss: 2.3206629753112793, train_acc: 74.07876586914062, train_loss: 2.3906190395355225, test_acc: 75.73725891113281\n",
      "Epoch 57, train_loss: 2.290513038635254, train_acc: 74.1435546875, train_loss: 2.357161521911621, test_acc: 75.8364486694336\n",
      "Epoch 58, train_loss: 2.2612388134002686, train_acc: 74.20657348632812, train_loss: 2.3249025344848633, test_acc: 75.93274688720703\n",
      "Epoch 59, train_loss: 2.232801914215088, train_acc: 74.26712799072266, train_loss: 2.2978451251983643, test_acc: 75.97660064697266\n",
      "Epoch 60, train_loss: 2.2048473358154297, train_acc: 74.33673858642578, train_loss: 2.2770965099334717, test_acc: 76.01642608642578\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(60):\n",
    "    for features, labels in train_ds:\n",
    "        model_train(features, labels)\n",
    "\n",
    "    for test_features, test_labels in test_ds:\n",
    "        model_validate(test_features, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, train_loss: {}, train_acc: {}, train_loss: {}, test_acc: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_acc.result()*100,\n",
    "                         valid_loss.result(),\n",
    "                         valid_acc.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist data loading from tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tfds.builder('mnist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,test_ds=mnist.as_dataset(split=[tfds.Split.TRAIN,tfds.Split.TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in train_ds:\n",
    "    image, label = features[\"image\"], features[\"label\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(32), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f71ec897860>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAORElEQVR4nO3df6jUdb7H8df7tmuRJtk9J5HW7tmWCOTG1WWQaEW7LXdJEUyk0mA9haBQgcYGyRYY+Uf2Q9eCXHRvspbWuqaRRWxrslTbH9IY3qMW/bhmqZw8R4TWRcKr+75/nG/L0c585jjf78x38v18wDAz3/d85vtu6OV35vuZOR9zdwG48P1L2Q0AaA3CDgRB2IEgCDsQBGEHgvhBK3fW0dHhXV1drdwlEMrBgwd17NgxG6qWK+xmdoukpyVdJOm/3X1F6vFdXV2qVqt5dgkgoVKp1Kw1/DbezC6S9Kyk6ZImSJpnZhMafT4AzZXnM/tkSZ+5+wF3PyXpD5JmFdMWgKLlCftVkg4Nun8423YWM1toZlUzq/b39+fYHYA8mn423t3XuXvF3SudnZ3N3h2AGvKE/Yik8YPu/yjbBqAN5Qn7+5KuNbMfm9kISXMlbS+mLQBFa3jqzd1Pm9l9kt7UwNTbenffX1hnAAqVa57d3d+Q9EZBvQBoIr4uCwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQLV2yGa134sSJZH3lypXJ+qOPPpqsT5s2LVl/8803a9ZGjBiRHIticWQHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYZ/8eOHr0aLK+ZcuWmrWXX345Ofbdd99N1s0sWX/77beT9Yceeqhm7cknn0yORbFyhd3MDko6IemMpNPuXimiKQDFK+LI/p/ufqyA5wHQRHxmB4LIG3aX9Gcz221mC4d6gJktNLOqmVX7+/tz7g5Ao/KGfYq7/1TSdEn3mtnUcx/g7uvcveLulc7Ozpy7A9CoXGF39yPZdZ+kVyRNLqIpAMVrOOxmNtLMLvv2tqRfSNpXVGMAipXnbPxYSa9k87A/kPSiu/+pkK6C6e3tTdbnzJmTrO/atavhfdf7Tfl1112XrPf09CTrp06dOu+e0BwNh93dD0j6jwJ7AdBETL0BQRB2IAjCDgRB2IEgCDsQBD9xbYGnn346WV+9enWy/uWXXza875tvvjlZX7NmTbJ++eWXJ+uLFi1K1h944IGatXr/Xbt3707W630jc8qUKcl6NBzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tlbYO3atcl6vfnm0aNHJ+upefwZM2Ykx3Z0dCTr9Wzbti1ZT83zHzp0KDn2wIEDyfrWrVuTdZyNIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME8ewGOHUuva/nNN9/kev7Fixcn6/Pnz8/1/Hk88cQTyfp7771XszZmzJjk2LvuuitZr/dbfZyNIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME8ewFOnjyZrJ85cybX8z/77LPJeqVSqVmbOXNmrn1v3LgxWV+6dGmyni3pPaTu7u7k2McffzxZx/mpe2Q3s/Vm1mdm+wZtu8LMdpjZp9l1+tsRAEo3nLfxv5d0yznblkra6e7XStqZ3QfQxuqG3d3fkXT8nM2zJG3Ibm+QdGvBfQEoWKMn6Ma6e292+ytJY2s90MwWmlnVzKr9/f0N7g5AXrnPxru7S/JEfZ27V9y9Um8hPgDN02jYj5rZOEnKrvuKawlAMzQa9u2Svp036Zb0ajHtAGiWuvPsZvaSpJskdZjZYUnLJK2Q9EczWyDpC0m3N7PJdnf11Vcn6yNHjsz1/MePn3t+9Gyp37M///zzybETJkxI1p966qlkvZ45c+bUrC1btizXc+P81A27u8+rUfp5wb0AaCK+LgsEQdiBIAg7EARhB4Ig7EAQ/MS1BR5++OFkffny5cn6J598kqx//fXXNWuzZs1Kjs3r4osvTtbXr19fs3bppZcW3Q4SOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBDMs7fAnXfemazfeOONyfrmzZuT9U2bNtWs7d+/Pzk2r/vvvz9ZHzVqVFP3j+HjyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDP3ga6urqS9QcffDBZ37VrV83avn37ataK8NhjjyXrqe8Q5F1OGueHIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME8+wXOzJL1ESNGJOvXX399sl6tVpP12267rWbtxRdfTI6dPXt2so7zU/fIbmbrzazPzPYN2vaImR0xsz3ZZUZz2wSQ13Dexv9e0i1DbP+Nu0/MLm8U2xaAotUNu7u/I+l4C3oB0ER5TtDdZ2Y92dv8MbUeZGYLzaxqZtX+/v4cuwOQR6Nh/62kn0iaKKlX0spaD3T3de5ecfdKZ2dng7sDkFdDYXf3o+5+xt3/Iel3kiYX2xaAojUUdjMbN+jubEnN/R0lgNzqzrOb2UuSbpLUYWaHJS2TdJOZTZTkkg5KWtTEHtFEl1xySbL+1ltvJeuvv/56sr5gwYKate7u7uTYtWvXJusbN25M1js6OpL1aOqG3d3nDbH5uSb0AqCJ+LosEARhB4Ig7EAQhB0IgrADQfATVySNHj06Wa+3HPXp06dr1u65557k2B07diTrkyenv8uV+gntDTfckBx7IeLIDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM+Oppo/f37N2pkzZ5Jjn3nmmWS9p6cnWV+5suYfUNKWLVuSYy9EHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2S8A48ePL7uFhtx9993J+syZM5P1adOmJeupP4O9efPm5Ng77rgjWf8+4sgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewz34BWLx4cc3aCy+8kBx78uTJZL3essmzZ89O1lOuvPLKZL2zszNZr/c37T/++OOateXLlyfHhpxnN7PxZvYXM/vQzPab2eJs+xVmtsPMPs2uxzS/XQCNGs7b+NOSfuXuEyTdIOleM5sgaamkne5+raSd2X0Abapu2N29190/yG6fkPSRpKskzZK0IXvYBkm3NqtJAPmd1wk6M+uSNEnSLklj3b03K30laWyNMQvNrGpm1f7+/hytAshj2GE3s1GStkpa4u5/G1xzd5fkQ41z93XuXnH3Sr0TLgCaZ1hhN7MfaiDom9x9W7b5qJmNy+rjJPU1p0UARag79WZmJuk5SR+5+6pBpe2SuiWtyK5fbUqHqOuaa66pWdu0aVNy7Ny5c5P1essqr1mzJlkf+N9naBMnTkyOrefzzz9veOxll12Wa9/fR8OZZ/+ZpF9K2mtme7Jtv9ZAyP9oZgskfSHp9ua0CKAIdcPu7n+VVOuf558X2w6AZuHrskAQhB0IgrADQRB2IAjCDgTBT1wvcNOnT0/WX3vttWR91apVyfr27duT9dQ8+969e5Njm2nSpEml7bssHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2YObOnVqrvqKFSuS9dQ8ez2rV69O1vv60n8vJbWU9ZIlSxrq6fuMIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBGEDi7m0RqVS8Wq12rL9AdFUKhVVq9Uhv9zAkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgqgbdjMbb2Z/MbMPzWy/mS3Otj9iZkfMbE92mdH8dgE0ajh/vOK0pF+5+wdmdpmk3Wa2I6v9xt2fal57AIoynPXZeyX1ZrdPmNlHkq5qdmMAinVen9nNrEvSJEm7sk33mVmPma03szE1xiw0s6qZVfv7+3M1C6Bxww67mY2StFXSEnf/m6TfSvqJpIkaOPKvHGqcu69z94q7Vzo7OwtoGUAjhhV2M/uhBoK+yd23SZK7H3X3M+7+D0m/kzS5eW0CyGs4Z+NN0nOSPnL3VYO2jxv0sNmS9hXfHoCiDOds/M8k/VLSXjPbk237taR5ZjZRkks6KGlRUzoEUIjhnI3/q6Shfh/7RvHtAGgWvkEHBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IoqVLNptZv6QvBm3qkHSsZQ2cn3btrV37kuitUUX29m/uPuTff2tp2L+zc7Oqu1dKayChXXtr174kemtUq3rjbTwQBGEHgig77OtK3n9Ku/bWrn1J9NaolvRW6md2AK1T9pEdQIsQdiCIUsJuZreY2cdm9pmZLS2jh1rM7KCZ7c2Woa6W3Mt6M+szs32Dtl1hZjvM7NPsesg19krqrS2W8U4sM17qa1f28uct/8xuZhdJ+kTSf0k6LOl9SfPc/cOWNlKDmR2UVHH30r+AYWZTJf1d0vPu/u/ZtickHXf3Fdk/lGPc/cE26e0RSX8vexnvbLWicYOXGZd0q6S7VOJrl+jrdrXgdSvjyD5Z0mfufsDdT0n6g6RZJfTR9tz9HUnHz9k8S9KG7PYGDfzP0nI1emsL7t7r7h9kt09I+naZ8VJfu0RfLVFG2K+SdGjQ/cNqr/XeXdKfzWy3mS0su5khjHX33uz2V5LGltnMEOou491K5ywz3javXSPLn+fFCbrvmuLuP5U0XdK92dvVtuQDn8Haae50WMt4t8oQy4z/U5mvXaPLn+dVRtiPSBo/6P6Psm1twd2PZNd9kl5R+y1FffTbFXSz676S+/mndlrGe6hlxtUGr12Zy5+XEfb3JV1rZj82sxGS5kraXkIf32FmI7MTJzKzkZJ+ofZbinq7pO7sdrekV0vs5Sztsox3rWXGVfJrV/ry5+7e8oukGRo4I/+/kh4qo4cafV0j6X+yy/6ye5P0kgbe1v2fBs5tLJD0r5J2SvpU0luSrmij3l6QtFdSjwaCNa6k3qZo4C16j6Q92WVG2a9doq+WvG58XRYIghN0QBCEHQiCsANBEHYgCMIOBEHYgSAIOxDE/wO7TDyA+IV4dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0].numpy().reshape((28,28)),cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Classification using tf.keras and Tensorboard for visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=np.array(X_train,np.float32),np.array(X_test,np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=X_train.reshape([-1,784]),X_test.reshape([-1,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already there\n"
     ]
    }
   ],
   "source": [
    "# Make a directory to keep the training logs\n",
    "if os.path.isdir(\"logs\"):\n",
    "    print('already there')\n",
    "else:\n",
    "    os.mkdir(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the callback\n",
    "logdir = \"logs\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dropout(rate=0.2, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5273), started 0:00:42 ago. (Use '!kill 5273' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbd04c63f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2403 - accuracy: 0.9270 - val_loss: 0.1283 - val_accuracy: 0.9611\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2082 - accuracy: 0.9366 - val_loss: 0.1108 - val_accuracy: 0.9660\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1918 - accuracy: 0.9415 - val_loss: 0.1076 - val_accuracy: 0.9664\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1796 - accuracy: 0.9446 - val_loss: 0.0943 - val_accuracy: 0.9715\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1682 - accuracy: 0.9479 - val_loss: 0.0990 - val_accuracy: 0.9687\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1617 - accuracy: 0.9497 - val_loss: 0.0888 - val_accuracy: 0.9738\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1513 - accuracy: 0.9531 - val_loss: 0.0860 - val_accuracy: 0.9757\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1480 - accuracy: 0.9545 - val_loss: 0.0831 - val_accuracy: 0.9734\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1416 - accuracy: 0.9560 - val_loss: 0.0810 - val_accuracy: 0.9758\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1386 - accuracy: 0.9564 - val_loss: 0.0817 - val_accuracy: 0.9742\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1353 - accuracy: 0.9572 - val_loss: 0.0762 - val_accuracy: 0.9783\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1327 - accuracy: 0.9589 - val_loss: 0.0812 - val_accuracy: 0.9760\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1295 - accuracy: 0.9600 - val_loss: 0.0745 - val_accuracy: 0.9770\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1245 - accuracy: 0.9610 - val_loss: 0.0762 - val_accuracy: 0.9775\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1225 - accuracy: 0.9616 - val_loss: 0.0742 - val_accuracy: 0.9767\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1257 - accuracy: 0.9597 - val_loss: 0.0735 - val_accuracy: 0.9779\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1195 - accuracy: 0.9626 - val_loss: 0.0732 - val_accuracy: 0.9776\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1193 - accuracy: 0.9627 - val_loss: 0.0750 - val_accuracy: 0.9785\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1170 - accuracy: 0.9621 - val_loss: 0.0741 - val_accuracy: 0.9782\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1156 - accuracy: 0.9636 - val_loss: 0.0694 - val_accuracy: 0.9784\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1137 - accuracy: 0.9637 - val_loss: 0.0707 - val_accuracy: 0.9779\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1148 - accuracy: 0.9631 - val_loss: 0.0747 - val_accuracy: 0.9776\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1141 - accuracy: 0.9644 - val_loss: 0.0713 - val_accuracy: 0.9796\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1116 - accuracy: 0.9652 - val_loss: 0.0722 - val_accuracy: 0.9789\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1072 - accuracy: 0.9661 - val_loss: 0.0724 - val_accuracy: 0.9784\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1128 - accuracy: 0.9646 - val_loss: 0.0717 - val_accuracy: 0.9793\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1085 - accuracy: 0.9661 - val_loss: 0.0719 - val_accuracy: 0.9788\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1078 - accuracy: 0.9656 - val_loss: 0.0749 - val_accuracy: 0.9782\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1069 - accuracy: 0.9667 - val_loss: 0.0739 - val_accuracy: 0.9784\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1103 - accuracy: 0.9649 - val_loss: 0.0708 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbcbb2b42e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/\n",
    "model.fit(X_train, Y_train,\n",
    "         validation_data=(X_test, Y_test),\n",
    "         batch_size=64,\n",
    "         epochs=30,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 5273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0708 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07084479398989352, 0.9787]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test,y=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 10682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
